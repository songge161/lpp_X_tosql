# app.py
# -*- coding: utf-8 -*-
import json
import re
from pathlib import Path
import streamlit as st
import time
from typing import Any, Dict

# é¡¶éƒ¨ import éƒ¨åˆ†
from backend.db import (
    init_db, list_tables, list_mapped_tables, save_table_mapping, soft_delete_table,
    restore_table, get_target_entity, get_priority,
    get_field_mappings, upsert_field_mapping, update_field_mapping, update_many_field_mappings,
    delete_field_mapping, get_table_script, save_table_script,
    export_all, import_all,
    rename_table_target_entity,
    list_table_targets,
    get_flow_entity_map, upsert_flow_entity_map, list_flow_entity_maps,
    list_file_mappings, upsert_file_mapping, delete_file_mapping
)
from backend.source_fields import detect_source_fields, detect_sql_path,detect_field_comments, detect_table_title
from backend.mapper_core import apply_record_mapping, check_entity_status, import_table_data, delete_table_data, clear_sql_cache, _parse_sql_file, _extract_entity_meta, _upsert_entity_row
from backend.sql_utils import update_runtime_db, current_cfg
from backend.presets import init_presets_db, list_presets, save_preset, delete_preset, get_last_runtime, save_last_runtime

try:
    from version3 import SID
except Exception:
    SID = "default_sid"

st.set_page_config(page_title="è¡¨æ˜ å°„ç®¡ç†å·¥å…·", layout="wide")
init_db()
init_presets_db()

# =============== ä¾§è¾¹æ ï¼šæ•°æ®åº“ä¸ SID é€‰æ‹© ===============
if "db_kind" not in st.session_state:
    st.session_state.db_kind = "mysql"
if "db_cfg" not in st.session_state:
    st.session_state.db_cfg = {
        "host": "127.0.0.1",
        "port": 3307,
        "user": "im",
        "password": "root",
        "database": "im",
        "charset": "utf8mb4",
        "autocommit": False,
        "schema": "public",  # ä»… PG ä½¿ç”¨
    }
if "current_sid" not in st.session_state:
    st.session_state.current_sid = SID
# å¯åŠ¨æ—¶å°è¯•æ¢å¤æœ€è¿‘ä¸€æ¬¡åº”ç”¨çš„è¿è¡Œæ—¶é…ç½®
_last = get_last_runtime()
if _last:
    st.session_state.db_kind = _last.get("kind") or st.session_state.db_kind
    st.session_state.db_cfg = {
        "host": _last.get("host", st.session_state.db_cfg.get("host")),
        "port": int(_last.get("port", st.session_state.db_cfg.get("port"))),
        "user": _last.get("user", st.session_state.db_cfg.get("user")),
        "password": _last.get("password", st.session_state.db_cfg.get("password")),
        "database": _last.get("database", st.session_state.db_cfg.get("database")),
        "charset": _last.get("charset", st.session_state.db_cfg.get("charset")),
        "autocommit": bool(_last.get("autocommit", st.session_state.db_cfg.get("autocommit"))),
        "schema": _last.get("schema", st.session_state.db_cfg.get("schema")),
    }
    # å…¼å®¹ï¼šå¦‚æ—  sid åˆ™å›é€€ä½¿ç”¨ schema
    st.session_state.current_sid = _last.get("sid") or _last.get("schema") or st.session_state.current_sid
    try:
        update_runtime_db(st.session_state.db_kind, st.session_state.db_cfg)
    except Exception as e:
        st.warning(f"æ¢å¤ä¸Šæ¬¡é…ç½®å¤±è´¥ï¼š{e}")

with st.sidebar:
    st.header("åº“/ç©ºé—´ç›®æ ‡")
    st.caption("åˆ—è¡¨ï¼šåç§°-sidï¼ˆåˆ é™¤ï¼šâŒï¼‰ï¼›æ”¯æŒæ·»åŠ ä¸åº”ç”¨")

    # é¢„è®¾åˆ—è¡¨ï¼šç‚¹å‡»å³åˆ‡æ¢
    presets = list_presets()
    if presets:
        for p in presets:
            disp_label = (p.get('name') or '').strip()
            # å…¼å®¹æ—§é¢„è®¾ï¼šæ—  sid åˆ™æ˜¾ç¤º schema
            sid_label = (p.get('sid') or p.get('schema') or '').strip()
            label = f"{disp_label}-{sid_label}" if sid_label else disp_label
            cols_row = st.columns([4, 1])
            with cols_row[0]:
                if st.button(label or "(æœªå‘½å)", key=f"preset_select_{p.get('name','')}"):
                    st.session_state["selected_preset_name"] = p.get("name")
                    st.session_state["selected_preset_label"] = label or p.get("name")
            with cols_row[1]:
                if st.button("âŒ", key=f"preset_del_{p.get('name','')}"):
                    try:
                        delete_preset(p.get("name"))
                        st.success("å·²åˆ é™¤é¢„è®¾")
                        st.rerun()
                    except Exception as e:
                        st.error(f"åˆ é™¤å¤±è´¥ï¼š{e}")
        if st.session_state.get("selected_preset_label"):
            st.caption(f"å·²é€‰ä¸­ï¼š{st.session_state.get('selected_preset_label')}")
    else:
        st.info("æš‚æ— é¢„è®¾ï¼Œè¯·ç‚¹å‡»ä¸‹æ–¹ã€æ·»åŠ ã€è¿›è¡Œåˆ›å»º")

    # äº¤äº’ï¼šæ·»åŠ  & åº”ç”¨
    ctrl_cols = st.columns([1, 1])
    with ctrl_cols[0]:
        if st.button("æ·»åŠ "):
            st.session_state["show_add_panel"] = True
    with ctrl_cols[1]:
        if st.button("åº”ç”¨"):
            sel_name = st.session_state.get("selected_preset_name")
            if not sel_name:
                st.warning("è¯·å…ˆåœ¨ä¸Šæ–¹åˆ—è¡¨é‡Œé€‰æ‹©ä¸€ä¸ªæ¡ç›®ã€‚")
            else:
                # æ‰¾åˆ°å¹¶åº”ç”¨
                presets = list_presets()
                target = next((x for x in presets if x.get("name") == sel_name), None)
                if not target:
                    st.warning("é€‰ä¸­çš„æ¡ç›®ä¸å­˜åœ¨ï¼Œè¯·åˆ·æ–°åé‡è¯•ã€‚")
                else:
                    st.session_state.db_kind = (target.get("kind") or st.session_state.db_kind)
                    st.session_state.db_cfg = {
                        "host": target.get("host") or st.session_state.db_cfg.get("host"),
                        "port": int(target.get("port") or st.session_state.db_cfg.get("port")),
                        "user": target.get("user") or st.session_state.db_cfg.get("user"),
                        "password": target.get("password") or st.session_state.db_cfg.get("password"),
                        "database": target.get("database") or st.session_state.db_cfg.get("database"),
                        "charset": target.get("charset") or st.session_state.db_cfg.get("charset"),
                        "autocommit": bool(target.get("autocommit") if target.get("autocommit") is not None else st.session_state.db_cfg.get("autocommit")),
                        # ç»Ÿä¸€ï¼šschema å³ä¸º SIDï¼›å…¼å®¹æ—§æ•°æ®ä½¿ç”¨ schema
                        "schema": target.get("sid") or target.get("schema") or st.session_state.db_cfg.get("schema"),
                    }
                    # åŒæ­¥å½“å‰ SIDï¼Œå…¼å®¹æ—§æ•°æ®
                    st.session_state.current_sid = target.get("sid") or target.get("schema") or st.session_state.current_sid
                    try:
                        update_runtime_db(st.session_state.db_kind, st.session_state.db_cfg)
                        save_last_runtime(st.session_state.db_kind, st.session_state.db_cfg, st.session_state.current_sid)
                        st.success("å·²åº”ç”¨é€‰ä¸­æ¡ç›®")
                    except Exception as e:
                        st.error(f"åº”ç”¨å¤±è´¥ï¼š{e}")
                    st.rerun()

    # æ·»åŠ é¢æ¿ï¼ˆå¼¹å‡ºå¼ï¼‰
    if st.session_state.get("show_add_panel"):
        with st.form("add_preset_form"):
            st.subheader("æ·»åŠ åº“è¿æ¥ä¸SID")
            preset_name = st.text_input("åç§°", value="")
            kind_label_to_val = {"mysql": "mysql", "postgres": "pg"}
            kind_choice = st.selectbox("æ•°æ®åº“ç±»å‹", options=list(kind_label_to_val.keys()), index=0)
            host_inp = st.text_input("ä¸»æœº", value=st.session_state.db_cfg.get("host", "127.0.0.1"))
            port_inp = st.number_input("ç«¯å£", value=int(st.session_state.db_cfg.get("port", 3306)), step=1)
            user_inp = st.text_input("ç”¨æˆ·", value=st.session_state.db_cfg.get("user", "root"))
            pwd_inp  = st.text_input("å¯†ç ", value=st.session_state.db_cfg.get("password", ""))
            db_inp   = st.text_input("åº“/æ•°æ®åº“", value=st.session_state.db_cfg.get("database", ""))
            # ç»Ÿä¸€ï¼šç©ºé—´å³ SID
            schema_inp = st.text_input("ç©ºé—´(sid)", value=st.session_state.db_cfg.get("schema", ""))

            c1, c2 = st.columns([1,1])
            with c1:
                do_save = st.form_submit_button("ä¿å­˜")
            with c2:
                do_cancel = st.form_submit_button("å–æ¶ˆ")

            if do_cancel:
                st.session_state["show_add_panel"] = False
                st.rerun()

            if do_save:
                name_norm = (preset_name or "").strip()
                if not name_norm:
                    st.warning("è¯·å¡«å†™é¢„è®¾åç§°ã€‚")
                elif not db_inp:
                    st.warning("è¯·å¡«å†™åº“/æ•°æ®åº“åç§°ã€‚")
                else:
                    try:
                        save_preset(
                            name=name_norm,
                            kind=kind_label_to_val.get(kind_choice, "mysql"),
                            host=host_inp,
                            port=int(port_inp or 0),
                            user=user_inp,
                            password=pwd_inp,
                            database=db_inp,
                            charset=st.session_state.db_cfg.get("charset"),
                            autocommit=st.session_state.db_cfg.get("autocommit"),
                            # åŒæ­¥ä¿å­˜ï¼šschema ä¸ sid ä½¿ç”¨åŒä¸€å€¼
                            schema=(schema_inp or None),
                            sid=(schema_inp or None),
                        )
                        # å…³é—­æ·»åŠ é¢æ¿å¹¶é€‰ä¸­æ–°å»ºæ¡ç›®
                        st.session_state["show_add_panel"] = False
                        new_label = f"{name_norm}-{(schema_inp or '').strip()}" if (schema_inp or '').strip() else name_norm
                        st.session_state["selected_preset_name"] = name_norm
                        st.session_state["selected_preset_label"] = new_label
                        st.success("âœ… é¢„è®¾å·²ä¿å­˜")
                        st.rerun()
                    except Exception as e:
                        st.error(f"ä¿å­˜å¤±è´¥ï¼š{e}")

    # æ‰¹æ¬¡ï¼ˆSIDï¼‰å•ç‹¬ç»´æŠ¤
    # å·²ç»Ÿä¸€ï¼šSID å³ä¸ºç©ºé—´(schema)ï¼Œä¸å†å•ç‹¬ç»´æŠ¤


# ================= å·¥å…·å‡½æ•° =================

def render_top_tabs(active: str):
    tabs = [
        ("home", "ğŸ ä¸»é¡µ"),
        ("mapped", "ğŸ§© æ˜ å°„ç»“æœç®¡ç†"),
        ("multi_mapping", "ğŸ§© å¤šæ˜ å°„ç®¡ç†ä¸­å¿ƒ"),
        ("flow", "ğŸ§° æµç¨‹ç®¡ç†"),
        ("user_dept", "ğŸ‘¥ ç”¨æˆ·éƒ¨é—¨ç®¡ç†"),
        ("file", "ğŸ“ƒ æ–‡ä»¶ç®¡ç†"),
    ]
    st.markdown(
        """
        <style>
        .top-tabs { display:flex; gap:8px; flex-wrap: wrap; margin:8px 0 14px; }
        .top-tabs a { font-size:15px; padding:8px 14px; line-height:1.3; border-radius:8px; border:1px solid #d0d0d0; background:#f7f7f7; text-decoration:none; color:#222; }
        .top-tabs a.active { background:#264653; color:#fff; border-color:#264653; }
        </style>
        """,
        unsafe_allow_html=True,
    )
    html = ["<div class='top-tabs'>"]
    for key, label in tabs:
        is_active = (key == (active or "")) or (key == "home" and (active or "") in ("list", "home"))
        cls = "active" if is_active else ""
        target_page = "home" if key == "home" else key
        html.append(f"<a class='{cls}' href='?page={target_page}'>{label}</a>")
    html.append("</div>")
    st.markdown("".join(html), unsafe_allow_html=True)

# è¯»å–æœ¬åœ° SQL æ–‡ä»¶çš„ INSERT è¡Œ
def _read_sql_rows(table: str):
    p = detect_sql_path(table)
    if not p.exists():
        return []
    return _parse_sql_file(p)

# é€‰æ‹©å­—æ®µåˆ—ç”¨äºå±•ç¤º
def _pick_cols(rows, cols):
    return [{k: r.get(k, "") for k in cols} for r in rows]

# ç»¼åˆæ„å»ºæµç¨‹å®ä¾‹æ‘˜è¦ï¼ˆåŸºäºæœ¬åœ° SQL æ–‡ä»¶ï¼‰
def _build_instance_rows():
    hi = _read_sql_rows("act_hi_procinst")
    ru_task = _read_sql_rows("act_ru_task")
    ru_exec = _read_sql_rows("act_ru_execution")
    ru_var  = _read_sql_rows("act_ru_variable")
    hi_task = _read_sql_rows("act_hi_taskinst")
    hi_act  = _read_sql_rows("act_hi_actinst")
    copies  = _read_sql_rows("bpm_process_instance_copy")
    def_info = _read_sql_rows("bpm_process_definition_info")
    cats    = _read_sql_rows("bpm_category")

    def _code_of(def_id):
        s = str(def_id or "")
        return s.split(":")[0] if ":" in s else s

    # æ˜ å°„ï¼šå®šä¹‰ç¼–ç  -> å®šä¹‰ä¿¡æ¯ / åˆ†ç±»åç§°
    def_by_code = {}
    for d in def_info:
        c = _code_of(d.get("process_definition_id"))
        def_by_code.setdefault(c, d)
    cat_name_by_code = {}
    for c in cats:
        try:
            del_flag = int(str(c.get("deleted", 0) or 0))
        except Exception:
            del_flag = 0
        if del_flag != 1:
            cat_name_by_code[str(c.get("code",""))] = c.get("name","")

    from collections import defaultdict
    def _group(rows, key):
        g = defaultdict(list)
        for r in rows:
            pid = str(r.get(key, "")).strip()
            if pid:
                g[pid].append(r)
        return g

    g_task = _group(ru_task, "proc_inst_id_")
    g_exec = _group(ru_exec, "proc_inst_id_")
    g_var  = _group(ru_var,  "proc_inst_id_")
    g_htask= _group(hi_task, "proc_inst_id_")
    g_hact = _group(hi_act,  "proc_inst_id_")
    g_copy = _group(copies,  "process_instance_id")

    rows = []
    for r in hi:
        pid = r.get("id_", "")
        def_id = r.get("proc_def_id_", "")
        code = _code_of(def_id)
        di = def_by_code.get(code, {})
        cat_name = cat_name_by_code.get(code, code)

        tasks = g_task.get(pid, [])
        execs = g_exec.get(pid, [])
        vars_ = g_var.get(pid, [])
        htasks= g_htask.get(pid, [])
        hacts = g_hact.get(pid, [])
        cps   = g_copy.get(pid, [])

        open_names = sorted({t.get("name_","") for t in tasks if t.get("name_")})
        assignees  = sorted({t.get("assignee_","") for t in tasks if t.get("assignee_")})
        act_ids    = sorted({e.get("act_id_","") for e in execs if e.get("act_id_")})

        # å˜é‡æ‘˜è¦ï¼šä»…å–å‰ 5 ä¸ª name_=value
        def _val(v):
            return v.get("text_") or v.get("double_") or v.get("long_") or ""
        var_pairs = [f"{v.get('name_','')}={_val(v)}" for v in vars_ if v.get("name_")]
        var_summary = ", ".join(var_pairs[:5])

        users = sorted({x.get("user_id") for x in cps if x.get("user_id")})

        rows.append({
            "proc_inst_id": pid,
            "proc_def_id": def_id,
            "def_code": code,
            "category": cat_name,
            "flow_define_name": r.get("name_",""),
            "business_key": r.get("business_key_",""),
            "start_time": r.get("start_time_",""),
            "end_time": r.get("end_time_",""),
            "open_task_count": len(tasks),
            "open_task_names": ",".join(open_names),
            "open_assignees": ",".join(assignees),
            "current_activities": ",".join(act_ids),
            "hist_task_count": len(htasks),
            "hist_act_count": len(hacts),
            "copy_count": len(cps),
            "copy_users": ",".join(map(str, users)),
            "def_desc": di.get("description",""),
            "form_type": di.get("form_type",""),
            "form_id": di.get("form_id",""),
            "vars": var_summary,
        })
    # æŒ‰å¼€å§‹æ—¶é—´å€’åº
    rows.sort(key=lambda x: str(x.get("start_time","")), reverse=True)
    return rows

# æ„å»ºå•ä¸ªæµç¨‹å®ä¾‹çš„ JSON é¢„è§ˆï¼ˆåŸºäº Flowable/Activiti act_* ä¸ bpm_* æœ¬åœ° SQLï¼‰
def _build_instance_json(proc_inst_id: str) -> Dict[str, Any]:
    pid = str(proc_inst_id or "").strip()
    if not pid:
        return {}
    hi = _read_sql_rows("act_hi_procinst")
    hist = next((r for r in hi if str(r.get("id_","")) == pid), None)
    if not hist:
        return {"procInstId": pid, "error": "not found in act_hi_procinst"}

    def _code_of(def_id):
        s = str(def_id or "")
        return s.split(":")[0] if ":" in s else s

    def_id = hist.get("proc_def_id_", "")
    def_code = _code_of(def_id)

    # è¿è¡Œæ—¶/å†å²æ˜ç»†
    ru_task = [r for r in _read_sql_rows("act_ru_task") if str(r.get("proc_inst_id_","")) == pid]
    ru_exec = [r for r in _read_sql_rows("act_ru_execution") if str(r.get("proc_inst_id_","")) == pid]
    ru_var  = [r for r in _read_sql_rows("act_ru_variable") if str(r.get("proc_inst_id_","")) == pid]
    hi_task = [r for r in _read_sql_rows("act_hi_taskinst") if str(r.get("proc_inst_id_","")) == pid]
    hi_act  = [r for r in _read_sql_rows("act_hi_actinst")  if str(r.get("proc_inst_id_","")) == pid]
    hi_var  = [r for r in _read_sql_rows("act_hi_varinst")  if str(r.get("proc_inst_id_","")) == pid]
    hi_cmts = [r for r in _read_sql_rows("act_hi_comment")  if str(r.get("proc_inst_id_","")) == pid]
    copies  = [r for r in _read_sql_rows("bpm_process_instance_copy") if str(r.get("process_instance_id","")) == pid]

    # å®šä¹‰ä¸åˆ†ç±»
    def_info_all = _read_sql_rows("bpm_process_definition_info")
    def_info = next((d for d in def_info_all if _code_of(d.get("process_definition_id")) == def_code), {})
    cats = _read_sql_rows("bpm_category")
    _cat_map = {}
    _cat_map_any = {}
    for c in cats:
        code = str(c.get("code",""))
        name = c.get("name","")
        _cat_map_any[code] = name
        try:
            del_flag = int(str(c.get("deleted", 0) or 0))
        except Exception:
            del_flag = 0
        if del_flag != 1:
            _cat_map[code] = name
    cat_name_by_code = _cat_map
    category_name = cat_name_by_code.get(def_code, def_code)
    flow_define_name = str(hist.get("name_", "") or "")

    # è¡¨å•ä¿¡æ¯
    form_preview = {}
    form_type = str(def_info.get("form_type",""))
    form_id = def_info.get("form_id")
    if form_type == "10" and form_id:
        forms = _read_sql_rows("bpm_form")
        fi = next((f for f in forms if str(f.get("id","")) == str(form_id)), None)
        if fi:
            form_preview = {
                "id": fi.get("id",""),
                "name": fi.get("name",""),
                "status": fi.get("status",""),
                "remark": fi.get("remark",""),
                "fields": fi.get("fields",""),
                "conf": fi.get("conf",""),
            }
    else:
        form_preview = {
            "form_type": form_type,
            "form_id": form_id or "",
            "form_fields": def_info.get("form_fields",""),
            "form_conf": def_info.get("form_conf",""),
        }

    # å˜é‡å½’å¹¶ä¸º name -> value
    def _var_value(v):
        return v.get("text_") or v.get("double_") or v.get("long_") or ""
    runtime_vars = {str(v.get("name_","")): _var_value(v) for v in ru_var if v.get("name_")}
    hist_vars    = {str(v.get("name_","")): _var_value(v) for v in hi_var if v.get("name_")}

    # è¿è¡Œæ—¶ä»»åŠ¡ä¸æ‰§è¡Œæ ‘ç²¾é€‰å­—æ®µ
    run_tasks = _pick_cols(ru_task, ["id_","name_","assignee_","owner_","create_time_","due_date_","category_","priority_","proc_inst_id_"])
    run_execs = _pick_cols(ru_exec, ["id_","parent_id_","super_exec_","act_id_","is_active_","is_concurrent_","is_scope_","proc_inst_id_"])
    # å†å²ä»»åŠ¡ä¸èŠ‚ç‚¹è½¨è¿¹ç²¾é€‰å­—æ®µ
    hist_tasks = _pick_cols(hi_task, [
        "id_","task_id_","name_","assignee_","owner_",
        "start_time_","end_time_","duration_",
        "delete_reason_","proc_inst_id_","parent_task_id_"
    ])
    hist_acts  = _pick_cols(hi_act,  ["id_","act_id_","act_name_","assignee_","start_time_","end_time_","task_id_","proc_inst_id_"])

    # æŠ„é€è®°å½•ç²¾é€‰å­—æ®µ
    copy_rows = _pick_cols(copies, ["id","user_id","start_user_id","task_id","task_name","category","process_instance_id","process_instance_name","create_time","update_time"]) 

    # æ±‡æ€» JSON
    # æ´»åŠ¨æµæ°´çº¿ï¼ˆæŒ‰å¼€å§‹æ—¶é—´æ’åºï¼‰
    pipeline = []
    acts_sorted = sorted(hi_act, key=lambda a: str(a.get("start_time_", "") or ""))
    for a in acts_sorted:
        ex = str(a.get("execution_id_", ""))
        tid = str(a.get("task_id_", ""))
        activity = {
            "id_": a.get("id_", ""),
            "act_id_": a.get("act_id_", ""),
            "act_name_": a.get("act_name_", ""),
            "act_type_": a.get("act_type_", ""),
            "assignee_": a.get("assignee_", ""),
            "start_time_": a.get("start_time_", ""),
            "end_time_": a.get("end_time_", ""),
            "duration_": a.get("duration_", ""),
            "task_id_": tid,
        }
        task_detail = next((t for t in hi_task if str(t.get("id_", "")) == tid), None)
        if not task_detail:
            task_detail = next((t for t in ru_task if str(t.get("id_", "")) == tid), None)
        comments = [
            {
                "id_": c.get("id_", ""),
                "time_": c.get("time_", ""),
                "user_id_": c.get("user_id_", ""),
                "action_": c.get("action_", ""),
                "message_": c.get("message_", ""),
            }
            for c in hi_cmts if str(c.get("task_id_", "")) == tid
        ]
        var_run = [
            {
                "name_": v.get("name_", ""),
                "value": _var_value(v),
                "create_time_": v.get("create_time_", ""),
                "last_updated_time_": v.get("last_updated_time_", ""),
            }
            for v in ru_var if str(v.get("execution_id_", "")) == ex
        ]
        var_hist = [
            {
                "name_": v.get("name_", ""),
                "value": _var_value(v),
                "create_time_": v.get("create_time_", ""),
                "last_updated_time_": v.get("last_updated_time_", ""),
            }
            for v in hi_var if str(v.get("execution_id_", "")) == ex
        ]
        pipeline.append({
            "activity": activity,
            "task": task_detail or {},
            "comments": comments,
            "variables": {"runtime": var_run, "history": var_hist},
        })

    # segmentsï¼šå°† sequenceFlow / exclusiveGateway å½’å…¥å‰åèŠ‚ç‚¹ä¹‹é—´çš„â€œç»ç”±â€é“¾è·¯ï¼Œä½¿å…³ç³»æ›´ç›´è§‚
    def _is_node(act_type: str) -> bool:
        t = (act_type or "").lower()
        return t in ("startevent", "usertask", "endevent")
    def _is_via(act_type: str) -> bool:
        t = (act_type or "").lower()
        return t in ("sequenceflow", "exclusivegateway")
    def _fmt_node(a: Dict[str, Any]) -> Dict[str, Any]:
        if not a:
            return {}
        return {
            "key": a.get("act_id_",""),
            "name": a.get("act_name_",""),
            "type": a.get("act_type_",""),
            "assignee": a.get("assignee_",""),
            "start": a.get("start_time_",""),
            "end": a.get("end_time_",""),
            "duration": a.get("duration_",""),
        }
    def _fmt_via(a: Dict[str, Any]) -> Dict[str, Any]:
        if not a:
            return {}
        return {
            "key": a.get("act_id_",""),
            "type": a.get("act_type_",""),
            "name": a.get("act_name_",""),
            "time": a.get("start_time_",""),
        }
    def _trim_task(t: Dict[str, Any]) -> Dict[str, Any]:
        if not t:
            return {}
        keys = [
            "id_","parent_task_id_",
            "name_","assignee_","owner_","start_time_","end_time_",
            "duration_","priority_","category_","delete_reason_",
        ]
        return {k: t.get(k, "") for k in keys}
    def _values_imp(entry: Dict[str, Any]) -> Dict[str, Any]:
        out = {}
        vv = []
        vhist = entry.get("variables", {}).get("history", [])
        vrun  = entry.get("variables", {}).get("runtime", [])
        vv.extend(vhist or [])
        vv.extend(vrun or [])
        def getv(name: str):
            for v in vv:
                if str(v.get("name_","")) == name:
                    return v.get("value","")
            return ""
        out["TASK_STATUS"] = getv("TASK_STATUS")
        out["TASK_REASON"] = getv("TASK_REASON")
        out["loopCounter"] = getv("loopCounter")
        assg = ""
        for v in vv:
            n = str(v.get("name_",""))
            if n.endswith("_assignee"):
                assg = v.get("value","")
                break
        out["assignee_var"] = assg
        return out
    def _last_comment(comments: Dict[str, Any]) -> Dict[str, Any]:
        cs = list(comments or [])
        if not cs:
            return {}
        cs.sort(key=lambda c: str(c.get("time_","")))
        last = cs[-1]
        return {"time": last.get("time_",""), "user_id": last.get("user_id_",""), "message": last.get("message_",""), "action": last.get("action_","")}
    def _actors(entry: Dict[str, Any]) -> Dict[str, Any]:
        s = set()
        act = entry.get("activity", {})
        t = entry.get("task", {})
        s.add(str(act.get("assignee_","")))
        s.add(str(t.get("assignee_","")))
        s.add(str(t.get("owner_","")))
        for c in entry.get("comments", []) or []:
            s.add(str(c.get("user_id_","")))
        s = {x for x in s if x and x != ""}
        return {"ids": sorted(list(s))}
    segments = []
    i = 0
    while i < len(pipeline):
        seg_from_entry = pipeline[i]
        a = seg_from_entry["activity"]
        if not _is_node(a.get("act_type_","")):
            i += 1
            continue
        via = []
        j = i + 1
        while j < len(pipeline):
            aj = pipeline[j]["activity"]
            if _is_via(aj.get("act_type_","")):
                via.append(_fmt_via(aj))
                j += 1
                continue
            # é‡åˆ°ä¸‹ä¸€èŠ‚ç‚¹åˆ™ç»“æŸå½“å‰åˆ†æ®µ
            break
        seg_to_entry = pipeline[j] if j < len(pipeline) else {"activity": {}}
        to_node = seg_to_entry.get("activity", {})
        for k in range(len(via)):
            if (via[k].get("type", "")).lower() == "sequenceflow" and not via[k].get("name"):
                guess = next((x.get("act_name_") for x in hi_act if str(x.get("act_id_", "")) == via[k].get("key", "") and x.get("act_name_")), "")
                if not guess:
                    guess = to_node.get("act_name_", "")
                via[k]["name"] = guess or via[k].get("name", "")
        segments.append({
            "from": _fmt_node(a),
            "via": via,
            "to": _fmt_node(to_node) if to_node else {},
            "to_task": _trim_task(seg_to_entry.get("task", {})) if to_node else {},
            "to_values": _values_imp(seg_to_entry) if to_node else {},
            "to_comment_last": _last_comment(seg_to_entry.get("comments", []) or []) if to_node else {},
            "to_actor_ids": _actors(seg_to_entry).get("ids", []) if to_node else [],
        })
        i = j if j > i else i + 1

    # ä»»åŠ¡ID â†’ æœ€è¿‘ä¸€æ¡æ‰¹æ³¨
    comments_by_task = {}
    try:
        tids = {str(t.get("id_","")) for t in hi_task if t.get("id_")}
        for tid in tids:
            cs = [c for c in hi_cmts if str(c.get("task_id_","")) == tid]
            comments_by_task[tid] = _last_comment(cs)
    except Exception:
        comments_by_task = {}

    out = {
        "procInstId": pid,
        "procDefId": def_id,
        "defCode": def_code,
        "processName": category_name,
        "flow_define_name": flow_define_name,
        "businessKey": hist.get("business_key_",""),
        "startTime": hist.get("start_time_",""),
        "endTime": hist.get("end_time_",""),
        "starterUserId": hist.get("start_user_id_",""),
        "definition": {
            "description": def_info.get("description",""),
            "modelId": def_info.get("model_id",""),
            "icon": def_info.get("icon",""),
            "formType": form_type,
            "formId": form_id or "",
            "categoryName": category_name,
            "flowDefineName": flow_define_name,
            "formPreview": form_preview,
        },
        "runtime": {
            "tasks": run_tasks,
            "executions": run_execs,
            "variables": runtime_vars,
        },
        "history": {
            "tasks": hist_tasks,
            "activities": hist_acts,
            "variables": hist_vars,
            "comments_by_task": comments_by_task,
        },
        "copies": copy_rows,
        "pipeline": pipeline,
        "segments": segments,
    }
    return out

# function _ensure_all_fields_seeded(table_name: str, target_entity: str)
def _ensure_all_fields_seeded(table_name: str, target_entity: str):
    """
    ä»…åœ¨é¦–æ¬¡è®¿é—®æŸè¡¨-å®ä½“ç»„åˆæ—¶æ‰§è¡Œä¸€æ¬¡å­—æ®µåˆå§‹åŒ–ã€‚
    - æŒ‰ (table_name, target_entity) ç»´åº¦åˆå§‹åŒ–
    - å·²å­˜åœ¨æ˜ å°„çš„å­—æ®µä¸ä¼šè¢«è¦†ç›–
    """
    cache_key = f"seeded_{table_name}_{target_entity or ''}"
    if st.session_state.get(cache_key):
        return

    # æŒ‰å½“å‰å®ä½“è¯»å–å·²å­˜åœ¨çš„å­—æ®µæ˜ å°„
    existing_mappings = get_field_mappings(table_name, target_entity or None)
    existing_fields = {m["source_field"] for m in existing_mappings}

    # ä»æº SQL æ£€æµ‹å­—æ®µ
    src_fields = detect_source_fields(table_name)

    # ä»…ä¸ºè¯¥å®ä½“ç¼ºå¤±çš„å­—æ®µåš upsertï¼Œtarget_paths é»˜è®¤ data.<åŒå>
    for f in src_fields:
        if f not in existing_fields:
            upsert_field_mapping(table_name, f, f"data.{f}", "", 1, 0, target_entity or "")

    st.session_state[cache_key] = True


def _parse_nth_insert(table_name: str, index: int = 0):
    p = detect_sql_path(table_name)
    if not p.exists():
        return None
    txt = p.read_text(encoding="utf-8", errors="ignore")
    inserts = list(re.finditer(
        r"insert\s+into\s+public\.\"?(?P<table>[\w\u4e00-\u9fa5]+)\"?"
        r"\s*\((?P<cols>[^)]*)\)\s*values\s*\((?P<vals>[\s\S]*?)\)\s*;",
        txt, re.IGNORECASE
    ))
    if not inserts or index >= len(inserts):
        return None
    m = inserts[index]
    cols = [c.strip().strip('"') for c in m.group("cols").split(",")]
    raw = m.group("vals")
    out, buf, in_str, i = [], [], False, 0
    while i < len(raw):
        ch = raw[i]
        if in_str:
            if ch == "'":
                if i + 1 < len(raw) and raw[i + 1] == "'":
                    buf.append("'"); i += 2
                else:
                    in_str = False; i += 1
            else:
                buf.append(ch); i += 1
        else:
            if ch == "'": in_str = True; i += 1
            elif ch == ",": out.append("".join(buf).strip()); buf = []; i += 1
            else: buf.append(ch); i += 1
    out.append("".join(buf).strip())
    # è½¬æ¢å€¼å¹¶è¿”å› dict
    def _convert(v: str):
        s = (v or "").strip()
        if s.lower() in ("null", "none"):
            return ""
        # å°è¯•æ•°å­—
        try:
            if s.startswith("-") or s.isdigit():
                return int(s)
        except Exception:
            pass
        try:
            if "." in s:
                return float(s)
        except Exception:
            pass
        return s
    vals = [_convert(x) for x in out]
    if len(cols) != len(vals):
        return None
    return dict(zip(cols, vals))


def _parse_all_inserts(table_name: str):
    p = detect_sql_path(table_name)
    if not p.exists():
        return []
    txt = p.read_text(encoding="utf-8", errors="ignore")
    inserts = list(re.finditer(
        r"insert\s+into\s+public\.\"?(?P<table>[\w\u4e00-\u9fa5]+)\"?"
        r"\s*\((?P<cols>[^)]*)\)\s*values\s*\((?P<vals>[\s\S]*?)\)\s*;",
        txt, re.IGNORECASE
    ))
    out_records = []
    for m in inserts:
        cols = [c.strip().strip('"') for c in m.group("cols").split(",")]
        raw = m.group("vals")
        # å¤ç”¨è§£æé€»è¾‘
        buf, items, in_str, i = [], [], False, 0
        while i < len(raw):
            ch = raw[i]
            if in_str:
                if ch == "'":
                    if i + 1 < len(raw) and raw[i + 1] == "'":
                        buf.append("'"); i += 2
                    else:
                        in_str = False; i += 1
                else:
                    buf.append(ch); i += 1
            else:
                if ch == "'": in_str = True; i += 1
                elif ch == ",": items.append("".join(buf).strip()); buf = []; i += 1
                else: buf.append(ch); i += 1
        items.append("".join(buf).strip())
        def _convert(v: str):
            s = (v or "").strip()
            if s.lower() in ("null", "none"):
                return ""
            try:
                if s.startswith("-") or s.isdigit():
                    return int(s)
            except Exception:
                pass
            try:
                if "." in s:
                    return float(s)
            except Exception:
                pass
            return s
        vals = [_convert(x) for x in items]
        if len(cols) == len(vals):
            out_records.append(dict(zip(cols, vals)))
    return out_records


_USER_MAP = None
_USER_NAME_MAP = None
_DEPT_MAP = None

def _user_dept_maps():
    global _USER_MAP, _USER_NAME_MAP, _DEPT_MAP
    if _USER_MAP is None:
        rows = _parse_all_inserts("sys_user")
        m = {}
        nmap = {}
        for r in rows:
            uid = str(r.get("user_id") or "").strip()
            if not uid:
                continue
            name = str(r.get("nick_name") or "").strip()
            dept_id = str(r.get("dept_id") or "").strip()
            prev = m.get(uid)
            if prev:
                if not prev.get("dept_id") and dept_id:
                    m[uid] = {"name": name, "dept_id": dept_id}
            else:
                m[uid] = {"name": name, "dept_id": dept_id}
            if name:
                prev = nmap.get(name)
                if dept_id:
                    nmap[name] = {"name": name, "dept_id": dept_id}
                elif not prev:
                    nmap[name] = {"name": name, "dept_id": dept_id}
        _USER_MAP = m
        _USER_NAME_MAP = nmap
    if _DEPT_MAP is None:
        rows = _parse_all_inserts("sys_dept")
        _DEPT_MAP = {str(r.get("dept_id") or "").strip(): str(r.get("dept_name") or r.get("name") or "").strip() for r in rows}
    return _USER_MAP, _DEPT_MAP

def _enrich_nodes_with_user(nodes):
    umap, dmap = _user_dept_maps()
    out = []
    for nd in nodes:
        t = nd.get("task") or {}
        assignee_id = str((t.get("assignee_") or nd.get("assignee") or "")).strip()
        info = umap.get(assignee_id)
        if not info and assignee_id:
            info = (_USER_NAME_MAP or {}).get(assignee_id)
        if info:
            nd["assignee_val"] = info.get("name","")
            dep = dmap.get(info.get("dept_id",""), "")
            if not dep and info.get("name"):
                aux = (_USER_NAME_MAP or {}).get(info.get("name",""))
                dep = dmap.get((aux or {}).get("dept_id",""), "") or dep
            nd["dept"] = dep
        out.append(nd)
    return out

def _build_flow_import_bundle(pid: str, match: Dict[str, Any] = None) -> Dict[str, Any]:
    data = _build_instance_json(pid)
    rt_vars_list = data.get("runtime", {}).get("variables", [])
    hi_vars_list = data.get("history", {}).get("variables", [])
    def _var_map(vs):
        if isinstance(vs, dict):
            return vs
        m = {}
        for v in vs or []:
            if isinstance(v, dict):
                n = str(v.get("name_",""))
                if n:
                    m[n] = v.get("value","")
        return m
    rt_vars_map = _var_map(rt_vars_list)
    hi_vars_map = _var_map(hi_vars_list)
    biz_name = str(rt_vars_map.get("businessName") or hi_vars_map.get("businessName") or "")
    segs = data.get("segments", []) or []
    nodes = []
    for idx in range(len(segs)):
        seg = segs[idx]
        frm = seg.get("from", {})
        via = seg.get("via", []) or []
        to_ = seg.get("to", {})
        if idx == 0:
            nodes.append({
                "id": frm.get("key",""),
                "type": frm.get("type",""),
                "name": frm.get("name",""),
                "assignee": frm.get("assignee",""),
                "start": frm.get("start",""),
                "end": frm.get("end",""),
                "duration": frm.get("duration",""),
                "next": {"to": to_.get("key",""), "via": via},
            })
        next_obj = {}
        if idx + 1 < len(segs):
            nxt = segs[idx + 1]
            nxt_from = nxt.get("from", {})
            if nxt_from.get("key") == to_.get("key"):
                next_obj = {"to": nxt.get("to", {}).get("key",""), "via": nxt.get("via", []) or []}
        lc = seg.get("to_comment_last", {})
        nodes.append({
            "id": to_.get("key",""),
            "type": to_.get("type",""),
            "name": to_.get("name",""),
            "assignee": to_.get("assignee",""),
            "start": to_.get("start",""),
            "end": to_.get("end",""),
            "duration": to_.get("duration",""),
            "lastComment": {"time": lc.get("time",""), "userId": lc.get("user_id",""), "message": lc.get("message","")},
            "task": seg.get("to_task", {}) or {},
            "value": seg.get("to_values", {}) or {},
            "actor_ids": seg.get("to_actor_ids", []) or [],
            "next": next_obj,
        })
    nodes = _enrich_nodes_with_user(nodes)
    assignees = {}
    for seg in segs:
        k = seg.get("to", {}).get("key","")
        a = seg.get("to_task", {}).get("assignee_","")
        if k:
            assignees[k] = a
    history_vars = {
        "processStatus": str(hi_vars_map.get("processStatus","")),
        "taskStatus": str(hi_vars_map.get("taskStatus") or hi_vars_map.get("TASK_STATUS") or ""),
        "taskReason": str(hi_vars_map.get("taskReason") or hi_vars_map.get("TASK_REASON") or ""),
        "nrOfInstances": str(hi_vars_map.get("nrOfInstances","")),
        "nrOfActiveInstances": str(hi_vars_map.get("nrOfActiveInstances","")),
        "nrOfCompletedInstances": str(hi_vars_map.get("nrOfCompletedInstances","")),
        "isSign": str(hi_vars_map.get("isSign","")),
        "assignees": assignees,
    }
    starter_code = str(data.get("starterUserId") or ((nodes[0] or {}).get("assignee") or ((nodes[0] or {}).get("task") or {}).get("assignee_") or "")).strip() if nodes else str(data.get("starterUserId") or "")
    preview_obj = {
        "meta": {
            "businessName": biz_name,
            "processName": data.get("defCode",""),
            "flowDefineName": data.get("flow_define_name",""),
            "startTime": data.get("startTime",""),
            "endTime": data.get("endTime",""),
            "icon": data.get("definition", {}).get("icon", ""),
            "starterCode": starter_code,
        },
        "variables": {"runtime": {}, "history": history_vars},
        "nodes": nodes,
    }
    def _flow_table(flow_name: str):
        fm = get_flow_entity_map(flow_name)
        return fm.get("source_table") or {
            "åˆä¼™åè®®": "ct_partner_agreement",
            "å‹Ÿé›†åè®®å®¡æ‰¹æµç¨‹": "ct_fund_base_info",
            "æ‰˜ç®¡åè®®æµç¨‹å®¡æ‰¹": "ct_fund_custody_agmt",
            "å…¶ä»–æµç¨‹": "ct_agreement_other",
            "é¡¹ç›®åˆè§„æ€§å®¡æŸ¥": "ct_project_base_info",
            "åŸºé‡‘å‡ºèµ„è®°å½•": "ct_invest_record",
            "é¡¹ç›®é€€å‡º": "ct_fund_quit_record",
            "ä¼šè®®ç®¡ç†å®¡æ‰¹æµç¨‹": "ct_meeting_manage",
            "ä¸šåŠ¡å®¡æ‰¹": "ct_fund_meet_manage",
            "åŸºé‡‘å…¬ç¤ºå®¡æ ¸": "ct_fund_publicity_review",
            "è‚¡æƒç›´æŠ•ä¸šåŠ¡å®¡æ‰¹": "ct_project_meet_manage",
            "è‚¡æƒç›´æŠ•ï¼Œå…¶ä»–åè®®": "ct_project_agreement_other",
        }.get(flow_name)
    fields_obj = {}
    fdef = str(data.get("flow_define_name",""))
    tbl = _flow_table(fdef)
    entity = ""
    out_name = ""
    type_override = ""
    used_match = None
    # é»˜è®¤å®ä½“ç±»å‹æ¥è‡ªæµç¨‹æ˜ å°„ï¼Œå³ä½¿æ²¡æœ‰æ ·ä¾‹åŒ¹é…
    fm0 = get_flow_entity_map(fdef)
    if fm0.get("target_entity"):
        entity = fm0.get("target_entity")
    if tbl:
        recs = _parse_all_inserts(tbl)
        mm = match if match is not None else next((r for r in recs if str(r.get("process_instance_id","")) == str(pid)), None)
        if mm:
            script = get_table_script(tbl, entity or None) or ""
            mapped, out_name, type_override = apply_record_mapping(tbl, mm, script, target_entity=entity or "")
            _ = _extract_entity_meta(mapped)
            fields_obj = mapped or {}
            used_match = mm
    src = json.dumps(preview_obj, ensure_ascii=False)
    esc = src.replace("'", "''")
    fields_obj = fields_obj or {}
    fields_obj["source_flow"] = esc
    try:
        raw = fields_obj.get("source_flow", "")
        parsed = json.loads(raw.replace("''", "'")) if raw else {}
    except Exception:
        parsed = preview_obj
    meta_info = parsed.get("meta", {}) or {}
    hist = (parsed.get("variables", {}) or {}).get("history", {}) or {}
    nodes_md = []
    def _fmt_duration_auto(v):
        if v in (None, ""):
            return ""
        s = str(v).strip()
        try:
            x = float(s)
        except Exception:
            return s
        secs = x / 1000.0 if x >= 1000 else x
        secs = int(secs)
        d = secs // 86400; secs %= 86400
        h = secs // 3600; secs %= 3600
        m = secs // 60; secs %= 60
        parts = []
        if d: parts.append(f"{d} å¤©")
        if h: parts.append(f"{h} å°æ—¶")
        if m: parts.append(f"{m} åˆ†é’Ÿ")
        if secs and not parts:
            parts.append(f"{secs} ç§’")
        return " ".join(parts) or "0 ç§’"
    def _fmt_time(v):
        if v in (None, ""):
            return ""
        s = str(v).strip()
        try:
            x = float(s)
            ms = int(x) if x >= 1e11 else int(x * 1000)
            from datetime import datetime
            dt = datetime.fromtimestamp(ms / 1000.0)
            return dt.strftime("%Y-%m-%d %H:%M:%S")
        except Exception:
            try:
                from datetime import datetime
                t = s.replace("T", " ").replace("Z", "")
                dt = datetime.fromisoformat(t)
                return dt.strftime("%Y-%m-%d %H:%M:%S")
            except Exception:
                return s
    def _ts_num(v):
        s = str(v or "").strip()
        if not s:
            return 0
        try:
            x = float(s)
            ms = int(x) if x >= 1e11 else int(x * 1000)
            return ms
        except Exception:
            try:
                from datetime import datetime
                t = s.replace("T", " ").replace("Z", "")
                return int(datetime.fromisoformat(t).timestamp() * 1000)
            except Exception:
                return 0
    nds_sorted = []
    nodes_src = (parsed.get("nodes", []) or [])
    for nd in nodes_src:
        t = nd.get("task", {}) or {}
        name0 = (t.get("name_") or nd.get("name", "") or "").strip()
        if name0 in ("å¼€å§‹", "ç»“æŸ"):
            continue
        nds_sorted.append(nd)
    if not nds_sorted and nodes_src:
        nds_sorted = nodes_src
    # æ’åºï¼šä»æ–°åˆ°æ—§ï¼ˆå¼€å§‹æ—¶é—´ä¼˜å…ˆï¼Œé™åºï¼‰
    nds_sorted.sort(key=lambda n: _ts_num((n.get("task") or {}).get("start_time_") or n.get("start", "") or (n.get("task") or {}).get("end_time_") or n.get("end", "")), reverse=True)
    # è¿½åŠ æœªå‡ºç°åœ¨èŠ‚ç‚¹ä¸­çš„çº¯ä»»åŠ¡ï¼ˆå¦‚ä»…åœ¨ act_hi_taskinst å­˜åœ¨çš„å­ä»»åŠ¡ï¼‰
    hist_tasks_list = (data.get("history", {}) or {}).get("tasks", []) or []
    present_ids = {str(((nd.get("task") or {}).get("id_")) or "").strip() for nd in nds_sorted}
    extra_nodes = []
    cm_map = ((data.get("history", {}) or {}).get("comments_by_task", {}) or {})
    for ht in hist_tasks_list:
        tid = str(ht.get("id_") or "").strip()
        if not tid or tid in present_ids:
            continue
        extra_nodes.append({
            "id": ht.get("task_id_", ""),
            "type": "userTask",
            "name": ht.get("name_", ""),
            "assignee": ht.get("assignee_", ""),
            "start": ht.get("start_time_", ""),
            "end": ht.get("end_time_", ""),
            "duration": ht.get("duration_", ""),
            "lastComment": cm_map.get(tid, {}) or {},
            "task": {
                "id_": ht.get("id_", ""),
                "parent_task_id_": ht.get("parent_task_id_", ""),
                "name_": ht.get("name_", ""),
                "assignee_": ht.get("assignee_", ""),
                "owner_": ht.get("owner_", ""),
                "start_time_": ht.get("start_time_", ""),
                "end_time_": ht.get("end_time_", ""),
                "duration_": ht.get("duration_", ""),
                "priority_": ht.get("priority_", ""),
                "category_": ht.get("category_", ""),
                "delete_reason_": ht.get("delete_reason_", ""),
            },
            "value": {},
            "actor_ids": [str(ht.get("assignee_", ""))],
            "next": {},
        })
    if extra_nodes:
        nds_sorted.extend(extra_nodes)
        nds_sorted = _enrich_nodes_with_user(nds_sorted)
    # çˆ¶å­ä»»åŠ¡å±•ç¤ºï¼šä¼˜å…ˆå±•ç¤ºçˆ¶ä»»åŠ¡ï¼Œå†å±•ç¤ºå…¶å­ä»»åŠ¡
    task_map = {}
    for nd in nds_sorted:
        t = nd.get("task") or {}
        tid = str(t.get("id_") or "").strip()
        if tid:
            task_map[tid] = nd
    from collections import defaultdict
    children_map = defaultdict(list)
    for nd in nds_sorted:
        t = nd.get("task") or {}
        p = str(t.get("parent_task_id_") or "").strip()
        if p:
            children_map[p].append(nd)
    visited = set()

    import re
    def _split_msg(s: str):
        s0 = (s or '').strip()
        inline_extra = ''
        suggest = ''
        parts = re.split(r"[ï¼Œ,]?\s*(?:ç†ç”±ä¸º|åŸå› æ˜¯)\s*[:ï¼š]", s0)
        if len(parts) >= 2:
            inline_extra = (parts[0] or '').strip().rstrip('ï¼Œã€‚')
            suggest = (parts[1] or '').strip().rstrip('ï¼Œã€‚')
            return inline_extra, suggest
        suggest = s0
        return inline_extra, suggest

    def _fmt_block(nd: Dict[str, Any], label_child: bool = False):
        t = nd.get("task", {}) or {}
        lc = nd.get("lastComment", {}) or {}
        rawm = (str(lc.get('message') or '') + ' ' + str(t.get('delete_reason_') or '')).lower()
        mk = 'âšª'
        for kw in ['åŒæ„','é€šè¿‡','æ‰¹å‡†','å®¡æ ¸é€šè¿‡']:
            if kw in rawm:
                mk = 'ğŸŸ¢'
                break
        if mk == 'âšª':
            for kw in ['é©³å›','é€€å›','æ‹’ç»','ä¸é€šè¿‡','ä¸åŒæ„']:
                if kw in rawm:
                    mk = 'ğŸ”´'
                    break
        task_name = (t.get('name_') or nd.get('name','') or '').strip()
        assignee = (t.get('assignee_') or nd.get('assignee','') or '').strip()
        start_txt = _fmt_time(t.get('start_time_') or nd.get('start',''))
        end_txt = _fmt_time(t.get('end_time_') or nd.get('end',''))
        dur_text = _fmt_duration_auto(t.get('duration_')) or _fmt_duration_auto(nd.get('duration'))
        msg = (lc.get('message') or '').strip()
        inline_extra, suggest_text = _split_msg(msg)
        if (not any([assignee, start_txt, end_txt, (dur_text or ''), msg])) and (task_name in ('ç»“æŸ','')):
            return []
        status_text = ("å®¡æ‰¹é€šè¿‡" if mk=='ğŸŸ¢' else ("å®¡æ‰¹æœªé€šè¿‡" if mk=='ğŸ”´' else ""))
        if (not str(meta_info.get('endTime','')).strip()) and mk == 'âšª':
            status_text = "å®¡æ‰¹ä¸­"
        # å•è¡ŒçŠ¶æ€ï¼šçˆ¶ä»»åŠ¡ç”¨â€œå®¡æ‰¹ä»»åŠ¡ï¼šxxxâ€ï¼Œå­ä»»åŠ¡ç”¨â€œxxxâ†’å­ä»»åŠ¡â€
        header = (f"**å®¡æ‰¹ä»»åŠ¡ï¼š{task_name} {mk}{(inline_extra or status_text)}**" if not label_child
                  else f"**{task_name}â†’å­ä»»åŠ¡ {mk}{(inline_extra or status_text)}**")
        out = [header, ""]
        av = str(nd.get("assignee_val") or "").strip()
        dp = str(nd.get("dept") or "").strip()
        disp = (f"{av}ï¼ˆ{dp}ï¼‰" if av and dp else (av or assignee))
        if disp:
            out.append(f"å®¡æ‰¹äººï¼š{disp}")
            out.append("")
        line = []
        if start_txt:
            line.append(f"åˆ›å»ºæ—¶é—´ï¼š{start_txt}")
        if end_txt:
            line.append(f"å®¡æ‰¹æ—¶é—´ï¼š {end_txt}")
        if dur_text:
            line.append(f"è€—æ—¶ï¼š {dur_text}")
        if line:
            out.append(" ".join(line))
            out.append("")
        out.append(f"å®¡æ‰¹å»ºè®®ï¼š{suggest_text}" if suggest_text else "å®¡æ‰¹å»ºè®®ï¼š")
        out.append("")
        return out

    for nd in nds_sorted:
        t = nd.get("task", {}) or {}
        tid = str(t.get("id_") or "").strip()
        if not tid or tid in visited:
            continue
        parent_id = str(t.get("parent_task_id_") or "").strip()
        if parent_id:
            pnd = task_map.get(parent_id)
            if pnd and str((pnd.get('task') or {}).get('id_') or '').strip() not in visited:
                nodes_md.extend(_fmt_block(pnd, label_child=False))
                visited.add(str((pnd.get('task') or {}).get('id_') or '').strip())
            nodes_md.extend(_fmt_block(nd, label_child=True))
            visited.add(tid)
            continue
        nodes_md.extend(_fmt_block(nd, label_child=False))
        visited.add(tid)
        for ch in children_map.get(tid, []):
            ctid = str((ch.get('task') or {}).get('id_') or '').strip()
            if ctid and ctid not in visited:
                nodes_md.extend(_fmt_block(ch, label_child=True))
                visited.add(ctid)
    hs_raw = str(hist.get('taskStatus','')).strip()
    code_map = {
        '0':'å¾…å®¡æ‰¹','1':'å®¡æ‰¹ä¸­','2':'å®¡æ‰¹é€šè¿‡','3':'å®¡æ‰¹ä¸é€šè¿‡','4':'å·²å–æ¶ˆ','5':'å·²å›é€€','6':'å§”æ´¾ä¸­','7':'å®¡æ‰¹é€šè¿‡ä¸­','8':'è‡ªåŠ¨æŠ„é€'
    }
    concl = code_map.get(hs_raw)
    if not concl:
        hs = hs_raw.lower()
        hmk = ''
        for kw in ['é€šè¿‡','åŒæ„','æ‰¹å‡†','å®¡æ ¸é€šè¿‡']:
            if kw in hs:
                hmk = 'å®¡æ ¸é€šè¿‡'
                break
        if not hmk:
            for kw in ['é©³å›','æ‹’ç»','ä¸é€šè¿‡','ä¸åŒæ„']:
                if kw in hs:
                    hmk = 'å®¡æ ¸æœªé€šè¿‡'
                    break
        concl = 'å®¡æ‰¹é€šè¿‡' if hmk=='å®¡æ ¸é€šè¿‡' else ('å®¡æ‰¹æœªé€šè¿‡' if hmk=='å®¡æ ¸æœªé€šè¿‡' else hs_raw)
    ended_raw = meta_info.get('endTime','')
    ended_flag = bool(str(ended_raw).strip())
    head_icon = 'ğŸŸ¢' if concl in ('å®¡æ‰¹é€šè¿‡','å®¡æ‰¹é€šè¿‡ä¸­') else ('ğŸ”´' if concl in ('å®¡æ‰¹æœªé€šè¿‡','å®¡æ‰¹ä¸é€šè¿‡') else 'âšª')
    header1 = f"**ç»“æŸæµç¨‹ï¼šåœ¨ {_fmt_time(ended_raw)} ç»“æŸ**"
    header2 = f"{head_icon} {concl}"
    nds = parsed.get("nodes", []) or []
    umap, _ = _user_dept_maps()
    scode = str(meta_info.get("starterCode") or "").strip()
    sname = (umap.get(scode) or {}).get("name", "")
    starter = sname or (str(nds[0].get("assignee_val") or ((nds[0].get("task") or {}).get("assignee_") or nds[0].get("assignee") or "")).strip() if nds else "")
    flow_name = str(meta_info.get("flowDefineName") or meta_info.get("processName") or "").strip()
    start_md = f"**å‘èµ·æµç¨‹ï¼šã€{starter}ã€‘åœ¨ {_fmt_time(meta_info.get('startTime',''))} å‘èµ·ã€ {flow_name} ã€‘æµç¨‹**"
    flow_md = "\n".join(([header1, header2, ""] if ended_flag else []) + nodes_md + ["", start_md]).strip()
    fields_obj["flow_md"] = flow_md
    # ç»Ÿä¸€è¡¥å…¨ï¼šç¡®ä¿ data ä¸­åŒ…å« name/type/id
    if (fields_obj.get("__name__") in (None, "")):
        fields_obj["__name__"] = biz_name
    type_name = (type_override or entity or tbl or fdef or "flow_instance")
    fields_obj["name"] = biz_name
    # ä»…é’ˆå¯¹æµç¨‹å…¥åº“ï¼šå½“æ˜ å°„æœªæä¾› bt æˆ–ä¸ºç©ºæ—¶ï¼Œç”¨ businessName å¡«å……
    if not str(fields_obj.get("bt", "")).strip():
        fields_obj["bt"] = biz_name
    fields_obj["type"] = type_name
    key_field = "id"
    key_val = fields_obj.get("id") or (used_match or {}).get("id") or str(pid or "")
    fields_obj["id"] = key_val
    meta = _extract_entity_meta(fields_obj)
    final_name = biz_name
    return {
        "fields_obj": fields_obj,
        "flow_md": flow_md,
        "meta": meta,
        "type_name": type_name,
        "key_field": key_field,
        "key_val": key_val,
        "final_name": final_name,
        "tbl": tbl,
        "entity": entity,
        "out_name": out_name,
        "type_override": type_override,
        "match": used_match,
    }

def _guess_table_display_name(table_name: str) -> str:
    """ä» DDL/æ³¨é‡ŠçŒœæµ‹ä¸­æ–‡åç§°ï¼šåŒ¹é… -- åç§°: xxx æˆ– /* name: xxx */ï¼Œå¦åˆ™è¿”å›æºè¡¨å"""
    p = detect_sql_path(table_name)
    if not p.exists():
        return table_name
    txt = p.read_text(encoding="utf-8", errors="ignore")
    m = re.search(r"--\s*(?:åç§°|name)\s*[:ï¼š]\s*([^\r\n]+)", txt, re.I)
    if m:
        return m.group(1).strip()
    m = re.search(r"/\*\s*(?:åç§°|name)\s*[:ï¼š]\s*([^\*]+)\*/", txt, re.I)
    if m:
        return m.group(1).strip()
    # é€€åŒ–ï¼šçœ‹ create table çš„æ³¨é‡Šè¡Œ
    m = re.search(r"comment\s+on\s+table\s+[\w\.\"']+\s+is\s+'([^']+)'", txt, re.I)
    if m:
        return m.group(1).strip()
    return table_name


# ================= è¯¦æƒ…é¡µï¼ˆåŸæœ‰ï¼‰ =================
def render_table_detail(table_name: str):
    comment_map = detect_field_comments(table_name)
    st.title(f"è¡¨é…ç½®ï¼š{table_name}")

    # æµ®åŠ¨å¯¼èˆªï¼ˆè¯¦æƒ…é¡µå¿«é€Ÿè·³è½¬ï¼‰
    st.markdown(
        """
        <style>
        .fixed-nav { position: fixed; top: 100px; right: 24px; background: rgba(30,30,30,0.9); color:#fff; padding: 10px 12px; border-radius: 10px; box-shadow: 0 4px 12px rgba(0,0,0,0.15); z-index: 9999; font-size: 13px; }
        .fixed-nav .title { font-weight: 600; margin-bottom: 8px; }
        .fixed-nav a { display:block; color:#fff; text-decoration: none; padding: 4px 0; }
        .fixed-nav a:hover { text-decoration: underline; }
        </style>
        <div class="fixed-nav">
          <div class="title">ğŸ” å¿«é€Ÿå¯¼èˆª</div>
          <a href="#sec-config">è¡¨é…ç½®</a>
          <a href="#sec-script">è¡¨çº§è„šæœ¬</a>
          <a href="#sec-mapping">å­—æ®µæ˜ å°„</a>
          <a href="#sec-add">æ–°å¢æ˜ å°„</a>
          <a href="#sec-print">æ¨¡æ‹Ÿæ‰“å°</a>
          <a href="#sec-focus">å­—æ®µä¸“æ³¨</a>
        </div>
        """,
        unsafe_allow_html=True,
    )

    # è¯»å–å½“å‰ entityï¼ˆä¼˜å…ˆä¼šè¯ï¼Œå…¶æ¬¡ URLï¼Œå†æ¬¡è¡¨é»˜è®¤ï¼‰
    current_entity = (
        st.session_state.get("current_entity")
        or st.query_params.get("entity", "")
        or get_target_entity(table_name)
    )
    st.session_state["current_entity"] = current_entity

    # âœ… æŒ‰å½“å‰å®ä½“åšé¦–æ¬¡å­—æ®µåˆå§‹åŒ–ï¼ˆä»…è¯¥å®ä½“ç¼ºå¤±çš„å­—æ®µï¼‰
    _ensure_all_fields_seeded(table_name, current_entity or "")

    # ç¼“å­˜å­—æ®µæ˜ å°„ï¼ˆæŒ‰ table + entity ç¼“å­˜ï¼‰
    cache_key = f"table_cache_{table_name}_{current_entity or ''}"
    if cache_key not in st.session_state:
        st.session_state[cache_key] = get_field_mappings(table_name, current_entity or None)
    mappings = st.session_state[cache_key]

    # è¡¨çº§é…ç½®ï¼ˆå½“å‰ç®¡ç†ç›®æ ‡ + è¯¥ç›®æ ‡çš„ä¼˜å…ˆçº§ï¼‰
    st.markdown("<div id=\"sec-config\"></div>", unsafe_allow_html=True)
    col1, col2 = st.columns([3, 1])
    with col1:
        # ç”¨å½“å‰ entity ä½œä¸ºé»˜è®¤ï¼Œå…è®¸è°ƒæ•´ï¼ˆä¿å­˜æ—¶æŒ‰å½“å‰ entity upsertï¼‰
        target_entity = st.text_input("å½“å‰ç®¡ç†ç›®æ ‡ entity", value=current_entity)
    with col2:
        # é’ˆå¯¹å½“å‰ç›®æ ‡è¯»å–ä¼˜å…ˆçº§
        priority = st.number_input("ä¼˜å…ˆçº§", value=get_priority(table_name, target_entity), step=1)

    if st.button("ä¿å­˜è¡¨é…ç½®", use_container_width=True):
        old_entity = (current_entity or "").strip()
        new_entity = (target_entity or "").strip()

        if not new_entity:
            st.warning("ç›®æ ‡ entity ä¸èƒ½ä¸ºç©ºã€‚")
        elif not old_entity:
            # è¯¦æƒ…é¡µä¸å…è®¸åˆ›å»ºæ–°ç›®æ ‡ï¼Œè¯·åˆ°ã€å¤šæ˜ å°„ç®¡ç†ä¸­å¿ƒã€
            st.warning("å½“å‰è¡¨æœªç»‘å®šç›®æ ‡ã€‚è¯·åˆ°ã€ğŸ§© å¤šæ˜ å°„ç®¡ç†ä¸­å¿ƒã€åˆ›å»ºç›®æ ‡å®ä½“ã€‚")
        elif new_entity != old_entity:
            # æ‰§è¡ŒåŸå­é‡å‘½åï¼šåŒæ—¶è¿ç§» table_map å’Œ field_map
            try:
                rename_table_target_entity(table_name, old_entity, new_entity)
            except Exception as e:
                st.error(f"é‡å‘½åå¤±è´¥ï¼š{e}")
            else:
                # åˆ‡æ¢ä¼šè¯ä¸ç¼“å­˜åˆ°æ–°ç›®æ ‡
                st.session_state["current_entity"] = new_entity
                st.session_state.pop(cache_key, None)
                new_cache_key = f"table_cache_{table_name}_{new_entity}"
                st.session_state[new_cache_key] = get_field_mappings(table_name, new_entity)

                # åŒæ­¥æ›´æ–° URL çš„ query å‚æ•°ï¼Œé¿å…ä¸‹ä¸€æ¬¡è¢«æ—§å€¼è¦†ç›–
                try:
                    st.query_params["page"] = "detail"
                    st.query_params["table"] = table_name
                    st.query_params["entity"] = new_entity
                except Exception:
                    st.experimental_set_query_params(page="detail", table=table_name, entity=new_entity)

                st.success(f"å·²é‡å‘½åï¼š{old_entity} â†’ {new_entity}")
                st.rerun()
        else:
            # åŒåï¼šä»…ä¿å­˜ä¼˜å…ˆçº§
            save_table_mapping(table_name, new_entity, priority)
            st.success("è¡¨é…ç½®å·²ä¿å­˜")

    st.caption(f"å½“å‰ç®¡ç†ç›®æ ‡ï¼š{target_entity or '(æœªæŒ‡å®šï¼Œä½¿ç”¨è¡¨é»˜è®¤)'}")
    st.markdown("---")

    # è¡¨çº§ Python è„šæœ¬
    st.markdown("<div id=\"sec-script\"></div>", unsafe_allow_html=True)
    st.subheader("è¡¨çº§ Python è„šæœ¬")
    st.caption("åœ¨å­—æ®µæ˜ å°„åæ‰§è¡Œï¼Œå¯ç›´æ¥ä¿®æ”¹ recordã€‚")
    # è¯»å–å½“å‰ entity çš„è„šæœ¬
    current_script = get_table_script(table_name, target_entity or st.session_state.get("current_entity") or "") or ""
    py_script = st.text_area("è‡ªå®šä¹‰è„šæœ¬", value=current_script, height=150)
    cols = st.columns([1, 1, 6])
    with cols[0]:
        if st.button("ä¿å­˜è„šæœ¬"):
            ok = save_table_script(table_name, py_script or "", target_entity=target_entity or st.session_state.get("current_entity") or "")
            if ok:
                st.success("è„šæœ¬å·²ä¿å­˜ï¼ˆå½“å‰ entityï¼‰")
            else:
                st.warning("å½“å‰ entity æœªåˆ›å»ºæ˜ å°„ï¼Œè¯·åˆ°ã€ğŸ§© å¤šæ˜ å°„ç®¡ç†ä¸­å¿ƒã€åˆ›å»ºç›®æ ‡å®ä½“")
    with cols[1]:
        if st.button("æ¸…ç©ºè„šæœ¬"):
            ok = save_table_script(table_name, "", target_entity=target_entity or st.session_state.get("current_entity") or "")
            if ok:
                st.success("è„šæœ¬å·²æ¸…ç©ºï¼ˆå½“å‰ entityï¼‰"); st.rerun()
            else:
                st.warning("å½“å‰ entity æœªåˆ›å»ºæ˜ å°„ï¼Œè¯·åˆ°ã€ğŸ§© å¤šæ˜ å°„ç®¡ç†ä¸­å¿ƒã€åˆ›å»ºç›®æ ‡å®ä½“")

    st.markdown("---")

    st.subheader("SQL ç¼“å­˜")
    ccols = st.columns([3, 1, 6])
    with ccols[0]:
        cache_tbl = st.text_input("è¡¨åï¼ˆç•™ç©ºæ¸…ç†å…¨éƒ¨ï¼‰", key=f"cache_tbl_{table_name}")
    with ccols[1]:
        if st.button("æ¸…ç†ä¸€æ¬¡", key=f"clear_sql_cache_{table_name}"):
            tbl = (cache_tbl or "").strip() or None
            info = clear_sql_cache(tbl)
            st.success(f"å·²æ¸…ç†ï¼šrows={info.get('rows',0)}, idx={info.get('idx',0)}")
            st.rerun()

    # å­—æ®µæ˜ å°„ï¼ˆå‹ç¼©è¡Œ + å•è¡Œä¿å­˜ + ä¸€é”®ä¿å­˜ï¼‰
    st.markdown("<div id=\"sec-mapping\"></div>", unsafe_allow_html=True)
    st.subheader("å­—æ®µæ˜ å°„é…ç½®ï¼ˆå‹ç¼©è¡Œæ˜¾ç¤ºï¼‰")
    st.caption("æ¯æ¡ä¸€è¡Œï¼šä¿®æ”¹åç‚¹ğŸ’¾ä¿å­˜ï¼›åº•éƒ¨æ”¯æŒä¸€é”®ä¿å­˜å…¨éƒ¨ã€‚")

    edited_data = []

    head = st.columns([2, 3, 4, 1, 1, 1])
    head[0].markdown("**å­—æ®µ**")
    head[1].markdown("**target_paths**")
    head[2].markdown("**rule**")
    head[3].markdown("**çŠ¶æ€**")
    head[4].markdown("**ä¿å­˜**")
    head[5].markdown("**åˆ é™¤**")

    for idx, m in enumerate(mappings):
        sfield = m["source_field"]
        t_key = f"tp_{table_name}_{idx}"
        r_key = f"rule_{table_name}_{idx}"

        cols = st.columns([2, 3, 4, 1, 1, 1])
        with cols[0]:
            label = sfield or "(è‡ªå®šä¹‰)"
            note = comment_map.get(sfield, "")
            st.text(f"{label}{f'ï¼ˆ{note}ï¼‰' if note else ''}")

        new_tpath = cols[1].text_input(label="", value=m["target_paths"], key=t_key, placeholder="target_paths")
        new_rule  = cols[2].text_input(label="", value=m["rule"],         key=r_key, placeholder="rule")

        changed = (new_tpath != m["target_paths"]) or (new_rule != m["rule"]) 
        if changed:
            m["target_paths"] = new_tpath
            m["rule"] = new_rule
            m["__changed__"] = True

        with cols[3]:
            st.markdown("ğŸŸ " if m.get("__changed__") else "âœ…")

        with cols[4]:
            if st.button("ğŸ’¾", key=f"save_row_{table_name}_{idx}"):
                update_field_mapping(table_name, sfield, m["target_paths"], m["rule"], target_entity or "")
                m.pop("__changed__", None)
                st.session_state[cache_key][idx] = m
                st.success(f"{sfield or '(è‡ªå®šä¹‰)'} å·²ä¿å­˜")
                st.rerun()

        with cols[5]:
            if st.button("ğŸ—‘", key=f"del_row_{table_name}_{idx}"):
                delete_field_mapping(table_name, sfield, target_entity or "")
                st.session_state[cache_key] = [x for x in st.session_state[cache_key] if x["source_field"] != sfield]
                st.success(f"{sfield or '(è‡ªå®šä¹‰)'} å·²åˆ é™¤")
                st.rerun()

        edited_data.append(m)

    st.markdown("---")
    if st.button("ğŸ’¾ ä¸€é”®ä¿å­˜å…¨éƒ¨ä¿®æ”¹", use_container_width=True):
        to_save = [m for m in edited_data if m.get("__changed__")]
        if to_save:
            update_many_field_mappings(table_name, to_save, target_entity or "")
            for m in to_save:
                m.pop("__changed__", None)
            st.session_state[cache_key] = edited_data
            st.success("âœ… æ‰€æœ‰ä¿®æ”¹å·²ä¿å­˜")
        else:
            st.info("æ²¡æœ‰éœ€è¦ä¿å­˜çš„å­—æ®µã€‚")

    st.markdown("---")
    # æ–°å¢è‡ªå®šä¹‰æ˜ å°„
    st.markdown("<div id=\"sec-add\"></div>", unsafe_allow_html=True)
    st.subheader("æ–°å¢è‡ªå®šä¹‰æ˜ å°„")
    with st.form(f"add_{table_name}"):
        src = st.text_input("source_fieldï¼ˆå¯ç©ºï¼‰")
        tgt = st.text_input("target_pathsï¼ˆä¾‹ï¼šdata.nameï¼‰")
        rule_new = st.text_input("ruleï¼ˆå¯ç©ºï¼‰")
        if st.form_submit_button("æ·»åŠ "):
            # æŸ¥é‡ï¼šå½“å‰ (table + entity) æ˜¯å¦å·²æœ‰ä¸€æ¡ç©º source_field çš„æ˜ å°„
            src_norm = (src or "").strip()
            existing_list = st.session_state.get(cache_key) or get_field_mappings(table_name, target_entity or None)
            has_empty_custom = any((m.get("source_field") or "") == "" for m in existing_list)

            if src_norm == "" and has_empty_custom:
                st.warning("å½“å‰å·²å­˜åœ¨ä¸€æ¡ source_field ä¸ºç©ºçš„è‡ªå®šä¹‰æ˜ å°„ï¼Œè¯·å¡«å†™ source_field æˆ–ä¿®æ”¹ç°æœ‰è®°å½•ã€‚")
            else:
                upsert_field_mapping(table_name, src_norm, tgt, rule_new, target_entity=target_entity or "")
                # åˆ·æ–°å½“å‰ table+entity çš„ç¼“å­˜ï¼Œç¡®ä¿æ–°æ˜ å°„ç«‹åˆ»å¯è§
                st.session_state[cache_key] = get_field_mappings(table_name, target_entity or None)
                st.success("å·²æ–°å¢æ˜ å°„")
                st.rerun()

    st.markdown("---")

    # æ¨¡æ‹Ÿæ‰“å°
    st.markdown("<div id=\"sec-print\"></div>", unsafe_allow_html=True)
    st.subheader("æ¨¡æ‹Ÿæ‰“å°")
    # è§£æå¹¶ç¼“å­˜å…¨éƒ¨æ ·ä¾‹è®°å½•
    samples_key = f"samples_{table_name}"
    if samples_key not in st.session_state:
        st.session_state[samples_key] = _parse_all_inserts(table_name)
    full_list = st.session_state[samples_key]

    # æŸ¥æ‰¾ç­›é€‰åŒºåŸŸ
    st.caption("æŸ¥æ‰¾æŒ‡å®šè®°å½•ï¼šå¡«å†™å­—æ®µåä¸å€¼ï¼Œæ”¯æŒéå”¯ä¸€åŒ¹é…")
    sf1, sf2, sf3, sf4 = st.columns([2, 2, 1, 1])
    with sf1:
        q_field = st.text_input("å­—æ®µå", key=f"q_field_{table_name}")
    with sf2:
        q_value = st.text_input("å­—æ®µå€¼", key=f"q_value_{table_name}")
    with sf3:
        q_contains = st.checkbox("åŒ…å«åŒ¹é…", value=True, key=f"q_contains_{table_name}")
    with sf4:
        do_query = st.button("æŸ¥è¯¢", key=f"do_query_{table_name}")

    filter_key = f"filter_{table_name}"
    idx_key = f"sample_idx_{table_name}"

    if do_query:
        fld = (q_field or "").strip()
        val = (q_value or "").strip()
        if fld and val:
            def _match(rec):
                rv = rec.get(fld)
                if rv is None:
                    return False
                s = str(rv)
                return (val in s) if q_contains else (s == val)
            st.session_state[filter_key] = [r for r in full_list if _match(r)]
            st.session_state[idx_key] = 0
            st.info(f"ç­›é€‰åˆ° {len(st.session_state[filter_key])} æ¡è®°å½•ï¼ˆæ€» {len(full_list)} æ¡ï¼‰")
        else:
            st.warning("è¯·å¡«å†™å­—æ®µåä¸å­—æ®µå€¼åå†æŸ¥è¯¢ã€‚")

    # æ¸…é™¤ç­›é€‰
    if st.button("æ¸…é™¤ç­›é€‰", key=f"clear_query_{table_name}"):
        st.session_state.pop(filter_key, None)
        st.session_state[idx_key] = 0

    idx_key = f"sample_idx_{table_name}"
    if idx_key not in st.session_state:
        st.session_state[idx_key] = 0
    sample_index = st.session_state[idx_key]

    # å½“å‰åˆ—è¡¨ï¼šä¼˜å…ˆè¿‡æ»¤ç»“æœ
    curr_list = st.session_state.get(filter_key) or full_list
    total_n = len(curr_list)
    st.caption(f"å½“å‰é¢„è§ˆç´¢å¼•ï¼š{sample_index + 1}/{max(total_n, 1)}ï¼ˆæ€» {len(full_list)} æ¡ï¼‰")

    cols_pg = st.columns([1, 1, 6])
    with cols_pg[0]:
        if st.button("â¬…ï¸ ä¸Šä¸€æ¡"):
            if sample_index > 0:
                st.session_state[idx_key] -= 1; st.rerun()
    with cols_pg[1]:
        if st.button("ä¸‹ä¸€æ¡ â¡ï¸"):
            if sample_index + 1 < total_n:
                st.session_state[idx_key] += 1; st.rerun()

    # å–å½“å‰æ ·ä¾‹
    sample = curr_list[sample_index] if (0 <= sample_index < total_n) else {}
    with st.expander("SQL æ ·ä¾‹è®°å½•", expanded=False):
        st.code(json.dumps(sample, ensure_ascii=False, indent=2))

    if st.button("ç”Ÿæˆæ¨¡æ‹Ÿæ‰“å°"):
        py_now = get_table_script(table_name, target_entity or st.session_state.get("current_entity") or "") or ""
        data_rec, out_name, type_override = apply_record_mapping(
            table_name, sample, py_now, target_entity=target_entity or st.session_state.get("current_entity") or ""
        )

        # â¬‡ï¸ æŠ½ meta å¹¶ä» data_rec ä¸­å‰”é™¤
        meta = _extract_entity_meta(data_rec)

        preview = {
            "uuid": "(mock uuid)",
            "sid": SID,
            "type": type_override or (target_entity or table_name),
            "name": out_name or "",
            "del": int(meta["del"]),
            "input_date": int(meta["input_date"]),
            "update_date": int(meta["update_date"]),
            "data": data_rec
        }
        st.success("ç”ŸæˆæˆåŠŸï¼š")
        st.code(json.dumps(preview, ensure_ascii=False, indent=2))

    # å­—æ®µä¸“æ³¨æ¨¡å¼
    st.markdown("<div id=\"sec-focus\"></div>", unsafe_allow_html=True)
    st.subheader("å­—æ®µä¸“æ³¨æ¨¡å¼")
    st.caption("å¡«å†™å­—æ®µåï¼ˆç”¨é€—å·åˆ†éš”ï¼‰ã€‚æ”¯æŒä¸¤ç§æ ¼å¼ï¼šnameï¼ˆå¤–å±‚ï¼‰ï¼Œdata.xxxï¼ˆæ˜ å°„åçš„ data å†…éƒ¨å­—æ®µï¼Œæ”¯æŒå¤šçº§ï¼‰ã€‚")
    focus_fields_key = f"focus_fields_{table_name}"
    focus_page_key = f"focus_page_{table_name}"
    focus_page_size_key = f"focus_page_size_{table_name}"

    ff_cols = st.columns([5, 1, 1, 1])
    with ff_cols[0]:
        fields_input = st.text_input("å­—æ®µåˆ—è¡¨", value=st.session_state.get(focus_fields_key, "name"))
    with ff_cols[1]:
        page_size = st.number_input("æ¯é¡µæ•°é‡", value=int(st.session_state.get(focus_page_size_key, 20)), min_value=5, max_value=200, step=5)
    with ff_cols[2]:
        gen_focus = st.button("ç”Ÿæˆ")
    with ff_cols[3]:
        clear_focus = st.button("æ¸…ç©º")

    # è§£æå­—æ®µåˆ—è¡¨
    def _parse_fields(s: str):
        return [x.strip() for x in (s or "").split(",") if x.strip()]

    if clear_focus:
        st.session_state.pop(focus_fields_key, None)
        st.session_state.pop(focus_page_key, None)
        st.session_state.pop(focus_page_size_key, None)

    if gen_focus:
        flds = _parse_fields(fields_input)
        if not flds:
            st.warning("è¯·å¡«å†™è‡³å°‘ä¸€ä¸ªå­—æ®µã€‚")
        else:
            st.session_state[focus_fields_key] = fields_input
            st.session_state[focus_page_key] = 0
            st.session_state[focus_page_size_key] = int(page_size)

    # è‹¥å·²æœ‰å­—æ®µé…ç½®ï¼ŒæŒ‰åˆ†é¡µæ‰“å°æ‰€æœ‰è®°å½•çš„å­—æ®µå€¼
    if focus_fields_key in st.session_state:
        flds = _parse_fields(st.session_state[focus_fields_key])
        page = int(st.session_state.get(focus_page_key, 0))
        size = int(st.session_state.get(focus_page_size_key, 20))

        # å½“å‰åˆ—è¡¨ï¼šä¼˜å…ˆè¿‡æ»¤ç»“æœ
        curr_list = st.session_state.get(filter_key) or full_list
        total_n = len(curr_list)
        total_pages = max(1, (total_n + size - 1) // size)
        start = page * size
        end = min(start + size, total_n)

        # é¡¶éƒ¨åˆ†é¡µä¿¡æ¯ä¸è·³è½¬
        pg_cols = st.columns([1, 1, 4])
        with pg_cols[0]:
            if st.button("â¬…ï¸ ä¸Šä¸€é¡µ", disabled=(page <= 0)):
                st.session_state[focus_page_key] = max(0, page - 1); st.rerun()
        with pg_cols[1]:
            if st.button("ä¸‹ä¸€é¡µ â¡ï¸", disabled=(page + 1 >= total_pages)):
                st.session_state[focus_page_key] = min(total_pages - 1, page + 1); st.rerun()
        with pg_cols[2]:
            st.caption(f"å½“å‰é¡µï¼š{page + 1}/{total_pages}ï¼ŒèŒƒå›´ {start + 1}-{end}ï¼Œæ€» {total_n} æ¡")

        # è®¡ç®—å½“å‰é¡µçš„æ˜ å°„å¹¶æŠ½å–å­—æ®µ
        py_now = get_table_script(table_name, target_entity or st.session_state.get("current_entity") or "") or ""
        rows = []
        def _get_data_path(d: dict, path: str):
            v = d
            for seg in [x for x in path.split(".") if x]:
                if isinstance(v, dict):
                    v = v.get(seg, "")
                else:
                    return ""
            return v if v is not None else ""

        for i, rec in enumerate(curr_list[start:end], start=start):
            data_rec, out_name, type_override = apply_record_mapping(
                table_name, rec, py_now, target_entity=target_entity or st.session_state.get("current_entity") or ""
            )
            name_val = (data_rec.get("__name__") or out_name or "")
            row = {"#": i + 1}
            for f in flds:
                if f == "name":
                    row[f] = name_val
                elif f.startswith("data."):
                    row[f] = _get_data_path(data_rec, f[5:])
                else:
                    # æœªçŸ¥æ ¼å¼ï¼Œå°è¯•ç›´æ¥å–æ˜ å°„åçš„é¡¶å±‚å­—æ®µ
                    row[f] = data_rec.get(f, "")
            rows.append(row)

        st.dataframe(rows, use_container_width=True)

    if st.button("è¿”å›åˆ—è¡¨"):
        st.session_state.page = "list"
        st.session_state.current_table = ""
        st.session_state.current_entity = ""
        st.rerun()


# ================= æ–°å¢ï¼šæ˜ å°„ç»“æœç®¡ç†é¡µ =================
def render_mapped_tables():
    st.title("ğŸ§© æ˜ å°„ç»“æœç®¡ç†")
    render_top_tabs('mapped')

    rows = list_mapped_tables()
    if not rows:
        st.info("æš‚æ— å·²è®¾ç½®æ˜ å°„çš„è¡¨ã€‚è¯·å…ˆåœ¨ã€æºè¡¨åˆ—è¡¨ã€é‡Œä¸ºè¡¨è®¾ç½® target_entityã€‚")
        return

    # é¡¶éƒ¨æ‰¹é‡æ“ä½œ
    c1, c2, c3 = st.columns([1,1,6])
    with c1:
        # æ‰¹é‡å…¥åº“æ–¹å¼é€‰æ‹©
        bulk_mode_label_to_val = {
            "åˆ›å»ºæ›´æ–°": "upsert",
            "ä»…æ›´æ–°": "update_only",
            "ä»…åˆ›å»º": "create_only",
        }
        bulk_mode = st.selectbox(
            "å…¥åº“æ–¹å¼",
            options=list(bulk_mode_label_to_val.keys()),
            index=0,
            key="bulk_import_mode"
        )
        if st.button("ä¸€é”®å…¥åº“ï¼ˆå…¨éƒ¨ï¼‰", type="primary"):
            total = 0
            progress_placeholder = st.empty()
            for r in rows:
                table = r["source_table"]
                start_ts = time.time()
                with progress_placeholder:
                    bar = st.progress(0, text=f"æ­£åœ¨å…¥åº“ï¼š{table}")
                def _fmt_eta(s):
                    try:
                        s = int(s)
                    except Exception:
                        s = 0
                    if s >= 3600:
                        h = s // 3600
                        m = (s % 3600) // 60
                        return f"{h}å°æ—¶{m}åˆ†"
                    m = s // 60
                    sec = s % 60
                    return f"{m:02d}:{sec:02d}"
                def _cb(done, all):
                    all = max(all, 1)
                    pct = int(done * 100 / all)
                    elapsed = max(time.time() - start_ts, 0.001)
                    eta = int((all - done) * (elapsed / max(done, 1)))
                    bar.progress(pct, text=f"æ­£åœ¨å…¥åº“ï¼š{table}ï¼ˆ{done}/{all}ï¼Œé¢„è®¡å‰©ä½™ {_fmt_eta(eta)}ï¼‰")
                total += import_table_data(
                    table,
                    sid=st.session_state.get("current_sid", SID),
                    target_entity_spec=r["target_entity"],
                    import_mode=bulk_mode_label_to_val.get(bulk_mode, "upsert"),
                    progress_cb=_cb
                )
            progress_placeholder.empty()
            st.success(f"âœ… å®Œæˆå…¥åº“ï¼ˆ{bulk_mode}ï¼‰ï¼Œæ€»è®¡å†™å…¥ {total} æ¡ã€‚")
    with c2:
        if st.button("ä¸€é”®åˆ é™¤ï¼ˆå…¨éƒ¨ï¼‰"):
            total_del = 0
            for r in rows:
                total_del += delete_table_data(r["target_entity"], sid=st.session_state.get("current_sid", SID)) 
            st.success(f"ğŸ—‘ å·²åˆ é™¤ {total_del} æ¡ï¼ˆæŒ‰ type æ±‡æ€»ï¼‰ã€‚")

    st.markdown("---")

    # è¡¨å¤´
    head = st.columns([3, 3, 3, 1, 1, 2])
    head[0].markdown("**åç§°**")
    head[1].markdown("**æºè¡¨**")
    head[2].markdown("**ç›®æ ‡ type**")
    head[3].markdown("**çŠ¶æ€**")
    head[4].markdown("**ä¼˜å…ˆåº¦**")
    head[5].markdown("**æ“ä½œ**")

    # æ¯è¡Œ
    for r in rows:
        src = r["source_table"]
        tgt = r["target_entity"]
        pri = r["priority"]
        disp_name = _guess_table_display_name(src)
        count = check_entity_status(tgt, sid=st.session_state.get("current_sid", SID))
        status = "âœ… å·²å…¥åº“" if count > 0 else "âŒ æœªå…¥åº“"

        cols = st.columns([3, 3, 3, 1, 1, 3])
        cols[0].text(disp_name)
        # è·³è½¬æ—¶æºå¸¦ entity å‚æ•°ï¼Œç›´è¾¾è¯¥ç›®æ ‡çš„è¯¦æƒ…é¡µï¼ˆæ–°æ ‡ç­¾é¡µæ‰“å¼€ï¼‰
        cols[1].markdown(
            f'<a href="?page=detail&table={src}&entity={tgt}" target="_blank">{src}</a>',
            unsafe_allow_html=True
        )
        cols[2].text(tgt)
        cols[3].text("âœ…" if count > 0 else "âŒ")
        cols[4].text(str(pri))

        with cols[5]:
            # è¡Œçº§å…¥åº“æ–¹å¼é€‰æ‹© + æ“ä½œæŒ‰é’®
            mode_label_to_val = {
                "åˆ›å»ºæ›´æ–°": "upsert",
                "ä»…æ›´æ–°": "update_only",
                "ä»…åˆ›å»º": "create_only",
            }
            row_mode_label = st.selectbox(
                "å…¥åº“æ–¹å¼",
                options=list(mode_label_to_val.keys()),
                index=0,
                key=f"mode_{src}_{tgt}"
            )
            b1, b2 = st.columns([1,1])
            with b1:
                if st.button("å…¥åº“", key=f"imp_{src}_{tgt}"):
                    progress_placeholder = st.empty()
                    start_ts = time.time()
                    bar = progress_placeholder.progress(0, text=f"æ­£åœ¨å…¥åº“ï¼š{src} â†’ {tgt}")
                    def _fmt_eta(s):
                        try:
                            s = int(s)
                        except Exception:
                            s = 0
                        if s >= 3600:
                            h = s // 3600
                            m = (s % 3600) // 60
                            return f"{h}å°æ—¶{m}åˆ†"
                        m = s // 60
                        sec = s % 60
                        return f"{m:02d}:{sec:02d}"
                    def _cb(done, all):
                        all = max(all, 1)
                        pct = int(done * 100 / all)
                        elapsed = max(time.time() - start_ts, 0.001)
                        eta = int((all - done) * (elapsed / max(done, 1)))
                        bar.progress(pct, text=f"æ­£åœ¨å…¥åº“ï¼š{src} â†’ {tgt}ï¼ˆ{done}/{all}ï¼Œé¢„è®¡å‰©ä½™ {_fmt_eta(eta)}ï¼‰")
                    n = import_table_data(
                        src,
                        sid=st.session_state.get("current_sid", SID),
                        target_entity_spec=tgt,
                        import_mode=mode_label_to_val.get(row_mode_label, "upsert"),
                        progress_cb=_cb
                    )
                    progress_placeholder.empty()
                    st.success(f"å…¥åº“å®Œæˆï¼ˆ{row_mode_label}ï¼‰ï¼šå†™å…¥ {n} æ¡")
                    st.rerun()
            with b2:
                if st.button("åˆ é™¤", key=f"del_{src}_{tgt}"):
                    n = delete_table_data(tgt, sid=st.session_state.get("current_sid", SID))
                    st.success(f"åˆ é™¤å®Œæˆï¼šæ¸…ç† {n} æ¡")
                    st.rerun()

# ==========================================================
# ğŸ§© å¤šæ˜ å°„ç®¡ç†é¡µï¼ˆæ”¯æŒå•è¡¨å¤š target_entityï¼‰
# ==========================================================
from backend.db import list_tables, list_table_targets, upsert_field_mapping,delete_table_mapping
from backend.mapper_core import import_table_data, delete_table_data, check_entity_status

@st.cache_data(ttl=30)
def _cached_list_tables():
    return [r[0] for r in list_tables()]

def render_multi_mapping():
    st.title("ğŸ§© å¤šæ˜ å°„ç®¡ç†ä¸­å¿ƒ")
    render_top_tabs('multi_mapping')

    rows = list_mapped_tables()
    if not rows:
        st.info("æš‚æ— å·²è®¾ç½®æ˜ å°„ç›®æ ‡ã€‚")
    else:
        c1, c2 = st.columns([1, 1])
        with c1:
            if st.button("â• æ–°å»ºæ˜ å°„ç›®æ ‡"):
                st.session_state["creating_map"] = True
        with c2:
            if st.button("ğŸ”„ åˆ·æ–°"):
                st.rerun()

        st.divider()

        for r in rows:
            src, tgt, desc = r["source_table"], r["target_entity"], r["description"]
            pri = r.get("priority", 0)
            cols = st.columns([3, 3, 3, 2])
            # æºè¡¨åˆ—æ”¹ä¸ºå¯ç‚¹å‡»è·³è¯¦æƒ…ï¼ˆæºå¸¦ entityï¼Œæ–°æ ‡ç­¾é¡µæ‰“å¼€ï¼‰
            cols[0].markdown(
                f'ğŸ—‚ï¸ <a href="?page=detail&table={src}&entity={tgt}" target="_blank"><code>{src}</code></a>',
                unsafe_allow_html=True
            )
            cols[1].markdown(f"ğŸ¯ `{tgt}`")
            new_desc = cols[2].text_input("æè¿°", value=desc or "", key=f"desc_{src}_{tgt}")
            with cols[3]:
                b1, b2 = st.columns([1,1])
                with b1:
                    if st.button("ä¿å­˜", key=f"save_{src}_{tgt}"):
                        save_table_mapping(src, tgt, pri, new_desc or "")
                        st.success("æè¿°å·²æ›´æ–°")
                        st.rerun()
                with b2:
                    if st.button("âŒ åˆ é™¤", key=f"del_{src}_{tgt}"):
                        # å¼¹å‡ºç¡®è®¤å±‚ï¼šæºå¸¦è¡¨/å®ä½“/æè¿°
                        st.session_state["confirm_del_show"] = True
                        st.session_state["confirm_del_src"] = src
                        st.session_state["confirm_del_tgt"] = tgt
                        st.session_state["confirm_del_desc"] = new_desc or ""

        # åˆ é™¤ç¡®è®¤å¼¹å±‚ï¼ˆå…¨å±€å”¯ä¸€ï¼‰
        if st.session_state.get("confirm_del_show"):
            st.warning(
                f"ç¡®è®¤åˆ é™¤è¯¥æ˜ å°„ï¼Ÿ\n\n- æºè¡¨ï¼š{st.session_state.get('confirm_del_src','')}\n- å®ä½“ï¼š{st.session_state.get('confirm_del_tgt','')}\n- æè¿°ï¼š{st.session_state.get('confirm_del_desc','')}\n\nåˆ é™¤åä¼šåŒæ—¶æ¸…ç†è¯¥å®ä½“ä¸‹çš„æ‰€æœ‰å­—æ®µæ˜ å°„ã€‚"
            )
            cdel = st.columns([1,1,6])
            with cdel[0]:
                if st.button("ç¡®å®šåˆ é™¤", key="confirm_delete_go"):
                    delete_table_mapping(st.session_state.get("confirm_del_src",""), st.session_state.get("confirm_del_tgt",""))
                    st.success("å·²åˆ é™¤æ˜ å°„ï¼Œå¹¶æ¸…ç†å¯¹åº”å­—æ®µ")
                    st.session_state["confirm_del_show"] = False
                    st.session_state.pop("confirm_del_src", None)
                    st.session_state.pop("confirm_del_tgt", None)
                    st.session_state.pop("confirm_del_desc", None)
                    st.rerun()
            with cdel[1]:
                if st.button("å–æ¶ˆ", key="confirm_delete_cancel"):
                    st.session_state["confirm_del_show"] = False
                    st.rerun()

            # ========== åˆ›å»ºæ–°æ˜ å°„å¼¹çª— ==========
        if st.session_state.get("creating_map"):
            st.subheader("â• æ–°å»ºæ˜ å°„ç›®æ ‡")
            table_name = st.text_input("æºè¡¨å")
            target_entity = st.text_input("ç›®æ ‡å®ä½“å")
            desc = st.text_input("æè¿°", "è‡ªåŠ¨ç”Ÿæˆçš„æ˜ å°„")
            pri = st.number_input("ä¼˜å…ˆçº§", value=0)
            if st.button("åˆ›å»ºæ˜ å°„"):
                save_table_mapping(table_name, target_entity, pri, desc)
                # âœ… æ–°å»ºåç«‹å³ä¸ºè¯¥å®ä½“ç”ŸæˆåŸºç¡€å­—æ®µæ˜ å°„ï¼ˆä¸è¦†ç›–æ—¢æœ‰å­—æ®µï¼‰
                _ensure_all_fields_seeded(table_name, target_entity or "")
                st.success("âœ… æ–°æ˜ å°„å·²åˆ›å»ºï¼Œå¹¶åˆå§‹åŒ–åŸºç¡€å­—æ®µæ˜ å°„")
                st.session_state["creating_map"] = False
                st.rerun()
        st.markdown("---")

# ================= åˆ—è¡¨é¡µï¼ˆåŸæœ‰ï¼‰ =================
def render_table_list():
    st.title("ğŸ  ä¸»é¡µ")
    render_top_tabs('list')

    top = st.columns([1,1,6])
    with top[0]:
        if st.button("å¯¼å‡ºé…ç½®"):
            cfg = export_all()
            st.download_button(
                "ä¸‹è½½ mapping_config.json",
                data=json.dumps(cfg, ensure_ascii=False, indent=2),
                file_name="mapping_config.json",
                mime="application/json",
                key="download_all_btn"
            )
    with top[1]:
        upf = st.file_uploader("å¯¼å…¥é…ç½®", type=["json"])
        if upf:
            obj = json.loads(upf.read().decode("utf-8"))
            import_all(obj)
            st.success("å¯¼å…¥å®Œæˆ"); st.rerun()

    st.markdown("---")

    # é¡¶éƒ¨å¯¼èˆªå·²åŒ…å«æ‰€æœ‰ç®¡ç†å…¥å£ï¼Œä¸»é¡µç»§ç»­ä¿ç•™å¯¼å‡º/å¯¼å…¥åŠŸèƒ½

    st.markdown("---")

    # æœç´¢ & å›æ”¶ç«™
    col_s = st.columns([3, 2])
    with col_s[0]:
        search = st.text_input("æœç´¢")
    with col_s[1]:
        show_disabled = st.checkbox("æ˜¾ç¤ºåœç”¨è¡¨", value=False)

    rows = list_tables(include_disabled=show_disabled)
    if search:
        rows = [r for r in rows if search.lower() in r[0].lower()]

    st.markdown("**æºè¡¨ | ç›®æ ‡entity | ä¼˜å…ˆçº§ | æ“ä½œ | çŠ¶æ€**")
    for src, tgt, pri, dis, desc in rows:
        col = st.columns([3, 3, 1, 1, 2])
        with col[0]:
            link = f"?page=detail&table={src}" + (f"&entity={tgt}" if (tgt or "").strip() else "")
            st.markdown(f"[{src}]({link})", unsafe_allow_html=True)
        with col[1]:
            st.text(tgt or "")
        with col[2]:
            st.text(str(pri))
        with col[3]:
            if dis:
                if st.button("æ¢å¤", key=f"res_{src}_{tgt}"):
                    restore_table(src); st.rerun()
            else:
                if st.button("åœç”¨", key=f"del_{src}_{tgt}"):
                    soft_delete_table(src); st.rerun()
        with col[4]:
            st.text("åœç”¨" if dis else "å¯ç”¨")

# ========== æ–°é¡µé¢ï¼šæµç¨‹ç®¡ç† / æ–‡ä»¶ç®¡ç† ==========

def render_flow_mgmt():
    st.title("ğŸ§° æµç¨‹ç®¡ç†")
    render_top_tabs('flow')
    super_tabs = st.tabs(["è¡¨å•è½¬æ¢ç®¡ç†", "è¡¨å•è½¬æ¢å…¥åº“", "åå°æ•°æ®"])

    with super_tabs[0]:
        st.subheader("è¡¨å•è½¬æ¢ç®¡ç†")
        kw = st.text_input("å…³é”®è¯ï¼ˆå®ä¾‹ID/ä¸šåŠ¡é”®/å®šä¹‰ç¼–ç ï¼‰", key="form_conv_kw")
        code_filter = st.text_input("æŒ‰å®šä¹‰ç¼–ç è¿‡æ»¤ï¼ˆå¦‚ ContractApprovalï¼‰", key="form_conv_code")
        rows = _build_instance_rows()
        flow_names_inst = {r.get("flow_define_name","") for r in rows if r.get("flow_define_name")}
        flow_names_cfg = {x.get("flow_define_name","") for x in list_flow_entity_maps()}
        flow_names = sorted({s for s in (flow_names_inst | flow_names_cfg) if s})
        flow_filter = st.selectbox("æŒ‰æµç¨‹åç§°è¿‡æ»¤ï¼ˆflowDefineNameï¼‰", options=["å…¨éƒ¨"] + flow_names, index=0, key="form_conv_flowname")
        def _match(r):
            s = (kw or "").strip().lower()
            ok_kw = (not s) or s in str(r.get("proc_inst_id","")) .lower() or s in str(r.get("business_key","")) .lower() or s in str(r.get("def_code","")) .lower()
            ok_code = (not code_filter) or str(r.get("def_code","")) == code_filter
            ok_flow = (flow_filter in ("å…¨éƒ¨", "", None)) or str(r.get("flow_define_name","")) == flow_filter
            return ok_kw and ok_code and ok_flow
        view = [r for r in rows if _match(r)]
        ids = [r.get("proc_inst_id") for r in view]
        pid = st.selectbox("é€‰æ‹©å®ä¾‹ID", options=ids or [""], index=0 if ids else None, key="form_conv_pid")
        if pid:
            data = _build_instance_json(pid)
            rt_vars_list = data.get("runtime", {}).get("variables", [])
            hi_vars_list = data.get("history", {}).get("variables", [])
            def _var_map(vs):
                if isinstance(vs, dict):
                    return vs
                m = {}
                for v in vs or []:
                    if isinstance(v, dict):
                        n = str(v.get("name_",""))
                        if n:
                            m[n] = v.get("value","")
                return m
            rt_vars_map = _var_map(rt_vars_list)
            hi_vars_map = _var_map(hi_vars_list)
            biz_name = str(rt_vars_map.get("businessName") or hi_vars_map.get("businessName") or "")
            if st.button("æŸ¥çœ‹é¢„è§ˆ", key=f"preview_{pid}"):
                st.session_state["flow_preview_pid"] = pid
            if st.session_state.get("flow_preview_pid") == pid:
                segs = data.get("segments", []) or []
                nodes = []
                for idx in range(len(segs)):
                    seg = segs[idx]
                    frm = seg.get("from", {})
                    via = seg.get("via", []) or []
                    to_ = seg.get("to", {})
                    if idx == 0:
                        nodes.append({
                            "id": frm.get("key",""),
                            "type": frm.get("type",""),
                            "name": frm.get("name",""),
                            "assignee": frm.get("assignee",""),
                            "start": frm.get("start",""),
                            "end": frm.get("end",""),
                            "duration": frm.get("duration",""),
                            "next": {"to": to_.get("key",""), "via": via},
                        })
                    next_obj = {}
                    if idx + 1 < len(segs):
                        nxt = segs[idx + 1]
                        nxt_from = nxt.get("from", {})
                        if nxt_from.get("key") == to_.get("key"):
                            next_obj = {"to": nxt.get("to", {}).get("key",""), "via": nxt.get("via", []) or []}
                    lc = seg.get("to_comment_last", {}) or {}
                    nodes.append({
                        "id": to_.get("key",""),
                        "type": to_.get("type",""),
                        "name": to_.get("name",""),
                        "assignee": to_.get("assignee",""),
                        "start": to_.get("start",""),
                        "end": to_.get("end",""),
                        "duration": to_.get("duration",""),
                        "lastComment": {"time": lc.get("time",""), "userId": lc.get("user_id",""), "message": lc.get("message","")},
                        "task": seg.get("to_task", {}) or {},
                        "value": seg.get("to_values", {}) or {},
                        "actor_ids": seg.get("to_actor_ids", []) or [],
                        "next": next_obj,
                    })
                assignees = {}
                for seg in segs:
                    k = seg.get("to", {}).get("key","")
                    a = seg.get("to_task", {}).get("assignee_","")
                    if k:
                        assignees[k] = a
                history_vars = {
                    "processStatus": str(hi_vars_map.get("processStatus","")),
                    "taskStatus": str(hi_vars_map.get("taskStatus") or hi_vars_map.get("TASK_STATUS") or ""),
                    "taskReason": str(hi_vars_map.get("taskReason") or hi_vars_map.get("TASK_REASON") or ""),
                    "nrOfInstances": str(hi_vars_map.get("nrOfInstances","")),
                    "nrOfActiveInstances": str(hi_vars_map.get("nrOfActiveInstances","")),
                    "nrOfCompletedInstances": str(hi_vars_map.get("nrOfCompletedInstances","")),
                    "isSign": str(hi_vars_map.get("isSign","")),
                    "assignees": assignees,
                }

                def _flow_table_map():
                    return {
                        "åˆä¼™åè®®": "ct_partner_agreement",
                        "å‹Ÿé›†åè®®å®¡æ‰¹æµç¨‹": "ct_fund_base_info",
                        "æ‰˜ç®¡åè®®æµç¨‹å®¡æ‰¹": "ct_fund_custody_agmt",
                        "å…¶ä»–æµç¨‹": "ct_agreement_other",
                        "é¡¹ç›®åˆè§„æ€§å®¡æŸ¥": "ct_project_base_info",
                        "åŸºé‡‘å‡ºèµ„è®°å½•": "ct_invest_record",
                        "é¡¹ç›®é€€å‡º": "ct_fund_quit_record",
                        "ä¼šè®®ç®¡ç†å®¡æ‰¹æµç¨‹": "ct_meeting_manage",
                        "ä¸šåŠ¡å®¡æ‰¹": "ct_fund_meet_manage",
                        "åŸºé‡‘å…¬ç¤ºå®¡æ ¸": "ct_fund_publicity_review",
                        "è‚¡æƒç›´æŠ•ä¸šåŠ¡å®¡æ‰¹": "ct_project_meet_manage",
                        "è‚¡æƒç›´æŠ•ï¼Œå…¶ä»–åè®®": "ct_project_agreement_other",
                    }
                def _flow_table(flow_name: str):
                    fm = get_flow_entity_map(flow_name)
                    return fm.get("source_table") or _flow_table_map().get(flow_name)

                fields_obj = {}
                fdef = str(data.get("flow_define_name",""))
                tbl = _flow_table(fdef)
                if tbl:
                    recs = _parse_all_inserts(tbl)
                    match = next((r for r in recs if str(r.get("process_instance_id","")) == str(pid)), None)
                    if match:
                        fm = get_flow_entity_map(fdef)
                        entity = (fm.get("target_entity") or get_target_entity(tbl) or "")
                        script = get_table_script(tbl, entity or None) or ""
                        mapped, _, _ = apply_record_mapping(tbl, match, script, target_entity=entity or "")
                        _ = _extract_entity_meta(mapped)
                        fields_obj = mapped or {}
                preview_obj = {
                    "meta": {
                        "businessName": biz_name,
                        "processName": data.get("defCode",""),
                        "flowDefineName": data.get("flow_define_name",""),
                        "startTime": data.get("startTime",""),
                        "endTime": data.get("endTime",""),
                        "icon": data.get("definition", {}).get("icon", ""),
                    },
                    "variables": {"runtime": {}, "history": history_vars, "fields": fields_obj},
                    "nodes": nodes,
                }
                st.json(preview_obj)

        st.markdown("---")
        st.subheader("æµç¨‹å­—æ®µæ˜ å°„ç®¡ç†")
        fmap = {
            "åˆä¼™åè®®": "ct_partner_agreement",
            "å‹Ÿé›†åè®®å®¡æ‰¹æµç¨‹": "ct_fund_base_info",
            "æ‰˜ç®¡åè®®æµç¨‹å®¡æ‰¹": "ct_fund_custody_agmt",
            "å…¶ä»–æµç¨‹": "ct_agreement_other",
            "é¡¹ç›®åˆè§„æ€§å®¡æŸ¥": "ct_project_base_info",
            "åŸºé‡‘å‡ºèµ„è®°å½•": "ct_invest_record",
            "é¡¹ç›®é€€å‡º": "ct_fund_quit_record",
            "ä¼šè®®ç®¡ç†å®¡æ‰¹æµç¨‹": "ct_meeting_manage",
            "ä¸šåŠ¡å®¡æ‰¹": "ct_fund_meet_manage",
            "åŸºé‡‘å…¬ç¤ºå®¡æ ¸": "ct_fund_publicity_review",
            "è‚¡æƒç›´æŠ•ä¸šåŠ¡å®¡æ‰¹": "ct_project_meet_manage",
            "è‚¡æƒç›´æŠ•ï¼Œå…¶ä»–åè®®": "ct_project_agreement_other",
        }
        for k, v in fmap.items():
            fm = get_flow_entity_map(k)
            curr_entity = fm.get("target_entity") or get_target_entity(v) or ""
            curr_table = fm.get("source_table") or v
            key_ent = f"flow_entity_custom_{k}"
            key_src = f"flow_source_custom_{k}"
            curr_link_entity = (str(st.session_state.get(key_ent) or "").strip() or str(curr_entity or "").strip())
            curr_link_table = (str(st.session_state.get(key_src) or "").strip() or str(curr_table or "").strip())
            c1, c2, c3, c4, c5 = st.columns([2, 2, 2, 2, 1])
            with c1:
                st.text(k)
            with c2:
                link = f"?page=detail&table={curr_link_table}"
                if curr_link_entity:
                    link += f"&entity={curr_link_entity}"
                st.markdown(f'ğŸ—‚ï¸ <a href="{link}" target="_blank"><code>{curr_link_table}</code></a>', unsafe_allow_html=True)
            with c3:
                custom_src = st.text_input("source_table", value=curr_table, key=key_src)
            with c4:
                custom_ent = st.text_input("entity", value=curr_entity, key=key_ent)
            with c5:
                if st.button("ä¿å­˜", key=f"flow_entity_save_{k}"):
                    src_val = (str(st.session_state.get(key_src) or custom_src or "").strip())
                    ent_val = (str(st.session_state.get(key_ent) or custom_ent or "").strip())
                    if src_val or ent_val:
                        if ent_val:
                            save_table_mapping(src_val, ent_val, 0, "")
                        upsert_flow_entity_map(k, src_val, ent_val)
                        st.success("å·²ä¿å­˜æµç¨‹æ˜ å°„")
                        st.rerun()

    with super_tabs[1]:
        st.subheader("è¡¨å•è½¬æ¢å…¥åº“")
        rows = _build_instance_rows()
        flow_names_inst = {r.get("flow_define_name","") for r in rows if r.get("flow_define_name")}
        flow_names_cfg = {x.get("flow_define_name","") for x in list_flow_entity_maps()}
        flow_names = sorted({s for s in (flow_names_inst | flow_names_cfg) if s})
        flow_sel = st.selectbox("æµç¨‹ç±»å‹(flowDefineName)", options=flow_names or [""])
        def _match_flow(r):
            return str(r.get("flow_define_name","")) == str(flow_sel)
        view = [r for r in rows if _match_flow(r)]
        pids = [r.get("proc_inst_id") for r in view]
        idx_key = f"flow_pid_idx_{flow_sel}"
        if idx_key not in st.session_state:
            st.session_state[idx_key] = 0
        index = st.session_state[idx_key]
        nav = st.columns([1, 1, 3])
        with nav[0]:
            if st.button("â¬…ï¸ ä¸Šä¸€æ¡", key=f"flow_prev_{flow_sel}"):
                if index > 0:
                    st.session_state[idx_key] = index - 1
                    st.rerun()
        with nav[1]:
            if st.button("ä¸‹ä¸€æ¡ â¡ï¸", key=f"flow_next_{flow_sel}"):
                if index + 1 < len(pids):
                    st.session_state[idx_key] = index + 1
                    st.rerun()
        with nav[2]:
            typed_pid = st.text_input("æŒ‡å®šå®ä¾‹ID", value="", key=f"flow_pid_input_{flow_sel}")
        final_pid = (typed_pid or "").strip() or (pids[index] if (0 <= index < len(pids)) else "")
        if final_pid and st.button("ç”Ÿæˆæ¨¡æ‹Ÿæ‰“å°", key=f"mock_print_{final_pid}"):
            data = _build_instance_json(final_pid)
            rt_vars_list = data.get("runtime", {}).get("variables", [])
            hi_vars_list = data.get("history", {}).get("variables", [])
            def _var_map(vs):
                if isinstance(vs, dict):
                    return vs
                m = {}
                for v in vs or []:
                    if isinstance(v, dict):
                        n = str(v.get("name_",""))
                        if n:
                            m[n] = v.get("value","")
                return m
            rt_vars_map = _var_map(rt_vars_list)
            hi_vars_map = _var_map(hi_vars_list)
            biz_name = str(rt_vars_map.get("businessName") or hi_vars_map.get("businessName") or "")
            segs = data.get("segments", []) or []
            nodes = []
            for idx in range(len(segs)):
                seg = segs[idx]
                frm = seg.get("from", {})
                via = seg.get("via", []) or []
                to_ = seg.get("to", {})
                if idx == 0:
                    nodes.append({
                        "id": frm.get("key",""),
                        "type": frm.get("type",""),
                        "name": frm.get("name",""),
                        "assignee": frm.get("assignee",""),
                        "start": frm.get("start",""),
                        "end": frm.get("end",""),
                        "duration": frm.get("duration",""),
                        "next": {"to": to_.get("key",""), "via": via},
                    })
                next_obj = {}
                if idx + 1 < len(segs):
                    nxt = segs[idx + 1]
                    nxt_from = nxt.get("from", {})
                    if nxt_from.get("key") == to_.get("key"):
                        next_obj = {"to": nxt.get("to", {}).get("key",""), "via": nxt.get("via", []) or []}
                lc = seg.get("to_comment_last", {}) or {}
                nodes.append({
                    "id": to_.get("key",""),
                    "type": to_.get("type",""),
                    "name": to_.get("name",""),
                    "assignee": to_.get("assignee",""),
                    "start": to_.get("start",""),
                    "end": to_.get("end",""),
                    "duration": to_.get("duration",""),
                    "lastComment": {"time": lc.get("time",""), "userId": lc.get("user_id",""), "message": lc.get("message","")},
                    "task": seg.get("to_task", {}) or {},
                    "value": seg.get("to_values", {}) or {},
                    "actor_ids": seg.get("to_actor_ids", []) or [],
                    "next": next_obj,
                })
            nodes = _enrich_nodes_with_user(nodes)
            assignees = {}
            for seg in segs:
                k = seg.get("to", {}).get("key","")
                a = seg.get("to_task", {}).get("assignee_","")
                if k:
                    assignees[k] = a
            history_vars = {
                "processStatus": str(hi_vars_map.get("processStatus","")),
                "taskStatus": str(hi_vars_map.get("taskStatus") or hi_vars_map.get("TASK_STATUS") or ""),
                "taskReason": str(hi_vars_map.get("taskReason") or hi_vars_map.get("TASK_REASON") or ""),
                "nrOfInstances": str(hi_vars_map.get("nrOfInstances","")),
                "nrOfActiveInstances": str(hi_vars_map.get("nrOfActiveInstances","")),
                "nrOfCompletedInstances": str(hi_vars_map.get("nrOfCompletedInstances","")),
                "isSign": str(hi_vars_map.get("isSign","")),
                "assignees": assignees,
            }
            starter_code = str(data.get("starterUserId") or ((nodes[0] or {}).get("assignee") or ((nodes[0] or {}).get("task") or {}).get("assignee_") or "")).strip() if nodes else str(data.get("starterUserId") or "")
            preview_obj = {
                "meta": {
                    "businessName": biz_name,
                    "processName": data.get("defCode",""),
                    "flowDefineName": data.get("flow_define_name",""),
                    "startTime": data.get("startTime",""),
                    "endTime": data.get("endTime",""),
                    "icon": data.get("definition", {}).get("icon", ""),
                    "starterCode": starter_code,
                },
                "variables": {"runtime": {}, "history": history_vars},
                "nodes": nodes,
            }
            def _flow_table(flow_name: str):
                fm = get_flow_entity_map(flow_name)
                return fm.get("source_table") or {
                    "åˆä¼™åè®®": "ct_partner_agreement",
                    "å‹Ÿé›†åè®®å®¡æ‰¹æµç¨‹": "ct_fund_base_info",
                    "æ‰˜ç®¡åè®®æµç¨‹å®¡æ‰¹": "ct_fund_custody_agmt",
                    "å…¶ä»–æµç¨‹": "ct_agreement_other",
                    "é¡¹ç›®åˆè§„æ€§å®¡æŸ¥": "ct_project_base_info",
                    "åŸºé‡‘å‡ºèµ„è®°å½•": "ct_invest_record",
                    "é¡¹ç›®é€€å‡º": "ct_fund_quit_record",
                    "ä¼šè®®ç®¡ç†å®¡æ‰¹æµç¨‹": "ct_meeting_manage",
                    "ä¸šåŠ¡å®¡æ‰¹": "ct_fund_meet_manage",
                    "åŸºé‡‘å…¬ç¤ºå®¡æ ¸": "ct_fund_publicity_review",
                    "è‚¡æƒç›´æŠ•ä¸šåŠ¡å®¡æ‰¹": "ct_project_meet_manage",
                    "è‚¡æƒç›´æŠ•ï¼Œå…¶ä»–åè®®": "ct_project_agreement_other",
                }.get(flow_name)
            fields_obj = {}
            fdef = str(data.get("flow_define_name",""))
            tbl = _flow_table(fdef)
            entity = ""
            out_name = ""
            type_override = ""
            if tbl:
                recs = _parse_all_inserts(tbl)
                match = next((r for r in recs if str(r.get("process_instance_id","")) == str(final_pid)), None)
                if match:
                    fm = get_flow_entity_map(fdef)
                    entity = (fm.get("target_entity") or get_target_entity(tbl) or "")
                    script = get_table_script(tbl, entity or None) or ""
                    mapped, out_name, type_override = apply_record_mapping(tbl, match, script, target_entity=entity or "")
                    _ = _extract_entity_meta(mapped)
                    fields_obj = mapped or {}
            src = json.dumps(preview_obj, ensure_ascii=False)
            esc = src.replace("'", "''")
            if fields_obj is None:
                fields_obj = {}
            fields_obj["source_flow"] = esc
            try:
                raw = fields_obj.get("source_flow", "")
                parsed = json.loads(raw.replace("''", "'")) if raw else {}
            except Exception:
                parsed = preview_obj
            meta_info = parsed.get("meta", {}) or {}
            hist = (parsed.get("variables", {}) or {}).get("history", {}) or {}
            nodes_md = []
            def _fmt_time(v):
                if v in (None, ""):
                    return ""
                s = str(v).strip()
                try:
                    x = float(s)
                    ms = int(x) if x >= 1e11 else int(x * 1000)
                    from datetime import datetime
                    dt = datetime.fromtimestamp(ms / 1000.0)
                    return dt.strftime("%Y-%m-%d %H:%M:%S")
                except Exception:
                    try:
                        from datetime import datetime
                        t = s.replace("T", " ").replace("Z", "")
                        dt = datetime.fromisoformat(t)
                        return dt.strftime("%Y-%m-%d %H:%M:%S")
                    except Exception:
                        return s
            def _fmt_duration_auto(v):
                if v in (None, ""):
                    return ""
                s = str(v).strip()
                try:
                    x = float(s)
                except Exception:
                    return s
                secs = x / 1000.0 if x >= 1000 else x
                secs = int(secs)
                d = secs // 86400; secs %= 86400
                h = secs // 3600; secs %= 3600
                m = secs // 60; secs %= 60
                parts = []
                if d: parts.append(f"{d} å¤©")
                if h: parts.append(f"{h} å°æ—¶")
                if m: parts.append(f"{m} åˆ†é’Ÿ")
                if secs and not parts:
                    parts.append(f"{secs} ç§’")
                return " ".join(parts) or "0 ç§’"
            def _ts_num(v):
                s = str(v or "").strip()
                if not s:
                    return 0
                try:
                    x = float(s)
                    ms = int(x) if x >= 1e11 else int(x * 1000)
                    return ms
                except Exception:
                    try:
                        from datetime import datetime
                        t = s.replace("T", " ").replace("Z", "")
                        return int(datetime.fromisoformat(t).timestamp() * 1000)
                    except Exception:
                        return 0
            nds_sorted = []
            nodes_src = (parsed.get("nodes", []) or [])
            for nd in nodes_src:
                t = nd.get("task", {}) or {}
                name0 = (t.get("name_") or nd.get("name", "") or "").strip()
                if name0 in ("å¼€å§‹", "ç»“æŸ"):
                    continue
                nds_sorted.append(nd)
            if not nds_sorted and nodes_src:
                nds_sorted = nodes_src
            # æ’åºï¼šä»æ–°åˆ°æ—§ï¼ˆå¼€å§‹æ—¶é—´ä¼˜å…ˆï¼Œé™åºï¼‰
            nds_sorted.sort(key=lambda n: _ts_num((n.get("task") or {}).get("start_time_") or n.get("start", "") or (n.get("task") or {}).get("end_time_") or n.get("end", "")), reverse=True)
            hist_tasks_list = (data.get("history", {}) or {}).get("tasks", []) or []
            present_ids = {str(((nd.get("task") or {}).get("id_")) or "").strip() for nd in nds_sorted}
            extra_nodes = []
            cm_map = ((data.get("history", {}) or {}).get("comments_by_task", {}) or {})
            for ht in hist_tasks_list:
                tid = str(ht.get("id_") or "").strip()
                if not tid or tid in present_ids:
                    continue
                extra_nodes.append({
                    "id": ht.get("task_id_", ""),
                    "type": "userTask",
                    "name": ht.get("name_", ""),
                    "assignee": ht.get("assignee_", ""),
                    "start": ht.get("start_time_", ""),
                    "end": ht.get("end_time_", ""),
                    "duration": ht.get("duration_", ""),
                    "lastComment": cm_map.get(tid, {}) or {},
                    "task": {
                        "id_": ht.get("id_", ""),
                        "parent_task_id_": ht.get("parent_task_id_", ""),
                        "name_": ht.get("name_", ""),
                        "assignee_": ht.get("assignee_", ""),
                        "owner_": ht.get("owner_", ""),
                        "start_time_": ht.get("start_time_", ""),
                        "end_time_": ht.get("end_time_", ""),
                        "duration_": ht.get("duration_", ""),
                        "priority_": ht.get("priority_", ""),
                        "category_": ht.get("category_", ""),
                        "delete_reason_": ht.get("delete_reason_", ""),
                    },
                    "value": {},
                    "actor_ids": [str(ht.get("assignee_", ""))],
                    "next": {},
                })
            if extra_nodes:
                nds_sorted.extend(extra_nodes)
                nds_sorted = _enrich_nodes_with_user(nds_sorted)
                nds_sorted.sort(key=lambda n: _ts_num((n.get("task") or {}).get("start_time_") or n.get("start", "") or (n.get("task") or {}).get("end_time_") or n.get("end", "")), reverse=True)
            # çˆ¶å­ä»»åŠ¡å±•ç¤ºï¼šä¼˜å…ˆå±•ç¤ºçˆ¶ä»»åŠ¡ï¼Œå†å±•ç¤ºå…¶å­ä»»åŠ¡ï¼ˆå•è¡ŒçŠ¶æ€ï¼‰
            task_map = {}
            for nd in nds_sorted:
                t0 = nd.get("task") or {}
                tid0 = str(t0.get("id_") or "").strip()
                if tid0:
                    task_map[tid0] = nd
            from collections import defaultdict
            children_map = defaultdict(list)
            for nd in nds_sorted:
                t0 = nd.get("task") or {}
                p0 = str(t0.get("parent_task_id_") or "").strip()
                if p0:
                    children_map[p0].append(nd)
            visited = set()
            import re
            def _split_msg(s: str):
                s0 = (s or '').strip()
                inline_extra = ''
                suggest = ''
                parts = re.split(r"[ï¼Œ,]?\s*(?:ç†ç”±ä¸º|åŸå› æ˜¯)\s*[:ï¼š]", s0)
                if len(parts) >= 2:
                    inline_extra = (parts[0] or '').strip().rstrip('ï¼Œã€‚')
                    suggest = (parts[1] or '').strip().rstrip('ï¼Œã€‚')
                    return inline_extra, suggest
                suggest = s0
                return inline_extra, suggest
            def _fmt_block(nd: Dict[str, Any], label_child: bool = False):
                t = nd.get("task", {}) or {}
                lc = nd.get("lastComment", {}) or {}
                rawm = (str(lc.get('message') or '') + ' ' + str(t.get('delete_reason_') or '')).lower()
                mk = 'âšª'
                for kw in ['åŒæ„','é€šè¿‡','æ‰¹å‡†','å®¡æ ¸é€šè¿‡']:
                    if kw in rawm:
                        mk = 'ğŸŸ¢'
                        break
                if mk == 'âšª':
                    for kw in ['é©³å›','é€€å›','æ‹’ç»','ä¸é€šè¿‡','ä¸åŒæ„']:
                        if kw in rawm:
                            mk = 'ğŸ”´'
                            break
                task_name = (t.get('name_') or nd.get('name','') or '').strip()
                assignee = (t.get('assignee_') or nd.get('assignee','') or '').strip()
                start_txt = _fmt_time(t.get('start_time_') or nd.get('start',''))
                end_txt = _fmt_time(t.get('end_time_') or nd.get('end',''))
                dur_text = _fmt_duration_auto(t.get('duration_')) or _fmt_duration_auto(nd.get('duration'))
                msg = (lc.get('message') or '').strip()
                inline_extra, suggest_text = _split_msg(msg)
                if (not any([assignee, start_txt, end_txt, (dur_text or ''), msg])) and (task_name in ('ç»“æŸ','')):
                    return []
                status_text = ("å®¡æ‰¹é€šè¿‡" if mk=='ğŸŸ¢' else ("å®¡æ‰¹æœªé€šè¿‡" if mk=='ğŸ”´' else ""))
                if (not str(meta_info.get('endTime','')).strip()) and mk == 'âšª':
                    status_text = "å®¡æ‰¹ä¸­"
                header = (f"**å®¡æ‰¹ä»»åŠ¡ï¼š{task_name} {mk}{(inline_extra or status_text)}**" if not label_child
                          else f"**{task_name}â†’å­ä»»åŠ¡ {mk}{(inline_extra or status_text)}**")
                out = [header, ""]
                av = str(nd.get("assignee_val") or "").strip()
                dp = str(nd.get("dept") or "").strip()
                disp = (f"{av}ï¼ˆ{dp}ï¼‰" if av and dp else (av or assignee))
                if disp:
                    out.append(f"å®¡æ‰¹äººï¼š{disp}")
                    out.append("")
                line = []
                if start_txt:
                    line.append(f"åˆ›å»ºæ—¶é—´ï¼š{start_txt}")
                if end_txt:
                    line.append(f"å®¡æ‰¹æ—¶é—´ï¼š {end_txt}")
                if dur_text:
                    line.append(f"è€—æ—¶ï¼š {dur_text}")
                if line:
                    out.append(" ".join(line))
                    out.append("")
                out.append(f"å®¡æ‰¹å»ºè®®ï¼š{suggest_text}" if suggest_text else "å®¡æ‰¹å»ºè®®ï¼š")
                out.append("")
                return out
            for nd in nds_sorted:
                t = nd.get("task", {}) or {}
                tid = str(t.get("id_") or "").strip()
                if not tid or tid in visited:
                    continue
                parent_id = str(t.get("parent_task_id_") or "").strip()
                if parent_id:
                    pnd = task_map.get(parent_id)
                    if pnd and str((pnd.get('task') or {}).get('id_') or '').strip() not in visited:
                        nodes_md.extend(_fmt_block(pnd, label_child=False))
                        visited.add(str((pnd.get('task') or {}).get('id_') or '').strip())
                    nodes_md.extend(_fmt_block(nd, label_child=True))
                    visited.add(tid)
                    continue
                nodes_md.extend(_fmt_block(nd, label_child=False))
                visited.add(tid)
                for ch in children_map.get(tid, []):
                    ctid = str((ch.get('task') or {}).get('id_') or '').strip()
                    if ctid and ctid not in visited:
                        nodes_md.extend(_fmt_block(ch, label_child=True))
                        visited.add(ctid)
            if not nodes_md:
                for tsk in (data.get("runtime", {}) or {}).get("tasks", []) or []:
                    name_rt = (tsk.get("name_", "") or "").strip()
                    assignee_rt = (tsk.get("assignee_", "") or "").strip()
                    start_txt_rt = _fmt_time(tsk.get("create_time_"))
                    nodes_md.append(f"**å®¡æ‰¹ä»»åŠ¡ï¼š{name_rt}**")
                    nodes_md.append("âšªå®¡æ‰¹ä¸­")
                    nodes_md.append("")
                    disp_rt = assignee_rt
                    if disp_rt:
                        nodes_md.append(f"å®¡æ‰¹äººï¼š{disp_rt}")
                        nodes_md.append("")
                    line_rt = []
                    if start_txt_rt:
                        line_rt.append(f"åˆ›å»ºæ—¶é—´ï¼š{start_txt_rt}")
                    if line_rt:
                        nodes_md.append(" ".join(line_rt))
                        nodes_md.append("")
                    nodes_md.append("å®¡æ‰¹å»ºè®®ï¼š")
                    nodes_md.append("")
            hs_raw = str(hist.get('taskStatus','')).strip()
            code_map = {
                '0':'å¾…å®¡æ‰¹','1':'å®¡æ‰¹ä¸­','2':'å®¡æ‰¹é€šè¿‡','3':'å®¡æ‰¹ä¸é€šè¿‡','4':'å·²å–æ¶ˆ','5':'å·²å›é€€','6':'å§”æ´¾ä¸­','7':'å®¡æ‰¹é€šè¿‡ä¸­','8':'è‡ªåŠ¨æŠ„é€'
            }
            concl = code_map.get(hs_raw)
            if not concl:
                hs = hs_raw.lower()
                hmk = ''
                for kw in ['é€šè¿‡','åŒæ„','æ‰¹å‡†','å®¡æ ¸é€šè¿‡']:
                    if kw in hs:
                        hmk = 'å®¡æ ¸é€šè¿‡'
                        break
                if not hmk:
                    for kw in ['é©³å›','æ‹’ç»','ä¸é€šè¿‡','ä¸åŒæ„']:
                        if kw in hs:
                            hmk = 'å®¡æ ¸æœªé€šè¿‡'
                            break
                concl = 'å®¡æ‰¹é€šè¿‡' if hmk=='å®¡æ ¸é€šè¿‡' else ('å®¡æ‰¹æœªé€šè¿‡' if hmk=='å®¡æ ¸æœªé€šè¿‡' else hs_raw)
            ended_raw = meta_info.get('endTime','')
            ended_flag = bool(str(ended_raw).strip())
            head_icon = 'ğŸŸ¢' if concl in ('å®¡æ‰¹é€šè¿‡','å®¡æ‰¹é€šè¿‡ä¸­') else ('ğŸ”´' if concl in ('å®¡æ‰¹æœªé€šè¿‡','å®¡æ‰¹ä¸é€šè¿‡') else 'âšª')
            header1 = f"**ç»“æŸæµç¨‹ï¼šåœ¨ {_fmt_time(ended_raw)} ç»“æŸ**"
            header2 = f"{head_icon} {concl}"
            nds = parsed.get("nodes", []) or []
            umap, _ = _user_dept_maps()
            scode = str(meta_info.get("starterCode") or "").strip()
            sname = (umap.get(scode) or {}).get("name", "")
            starter = sname or (str(nds[0].get("assignee_val") or ((nds[0].get("task") or {}).get("assignee_") or nds[0].get("assignee") or "")).strip() if nds else "")
            flow_name = str(meta_info.get("flowDefineName") or meta_info.get("processName") or "").strip()
            start_md = f"**å‘èµ·æµç¨‹ï¼šã€{starter}ã€‘åœ¨ {_fmt_time(meta_info.get('startTime',''))} å‘èµ·ã€ {flow_name} ã€‘æµç¨‹**"
            flow_md = "\n".join(([header1, header2, ""] if ended_flag else []) + nodes_md + ["", start_md]).strip()
            fields_obj["flow_md"] = flow_md
            meta = _extract_entity_meta(fields_obj)
            entity_obj = {
                "uuid": "(mock uuid)",
                "sid": st.session_state.get("current_sid", SID),
                "type": type_override or (entity or tbl or ""),
                "name": out_name or "",
                "del": int(meta.get("del", 0)),
                "input_date": int(meta.get("input_date", 0)),
                "update_date": int(meta.get("update_date", 0)),
                "data": fields_obj,
            }
            st.code(json.dumps(entity_obj, ensure_ascii=False, indent=2))
            md = str(fields_obj.get("flow_md", "")).strip()
            if md:
                st.markdown(md)

        write_mode = st.selectbox(
            "å†™å…¥æ¨¡å¼",
            options=["åˆå¹¶å†™å…¥ï¼ˆé»˜è®¤ï¼‰", "ä»…ä¿å­˜ source_flow/flow_md è¦†ç›–"],
            index=0,
            key=f"flow_write_mode_{flow_sel}"
        )
        if typed_pid and st.button("å…¥åº“å½“å‰", key=f"import_{final_pid}"):
            bundle = _build_flow_import_bundle(final_pid)
            fields_obj = bundle.get("fields_obj") or {}
            flow_md = bundle.get("flow_md") or ""
            meta = bundle.get("meta") or {}
            type_name = bundle.get("type_name") or ""
            key_field = bundle.get("key_field") or "id"
            key_val = bundle.get("key_val") or ""
            final_name = bundle.get("final_name") or ""
            used_match = bundle.get("match")
            if write_mode == "ä»…ä¿å­˜ source_flow/flow_md è¦†ç›–":
                key_val = (used_match or {}).get("id") or key_val or str(final_pid or "")
                if fields_obj.get("id") in (None, "") and key_val:
                    fields_obj["id"] = key_val
                cover_obj = {
                    key_field: key_val,
                    "name": fields_obj.get("name", ""),
                    "bt": fields_obj.get("bt", ""),
                    "type": fields_obj.get("type", type_name),
                    "source_flow": fields_obj.get("source_flow",""),
                    "flow_md": flow_md
                }
                data_json = json.dumps(cover_obj, ensure_ascii=False)
                import_mode = "upsert_replace"
                sid = st.session_state.get("current_sid", SID)
                wrote = _upsert_entity_row(type_name, key_field, key_val, sid, final_name, data_json, meta, import_mode=import_mode)
                st.success(f"å…¥åº“å®Œæˆï¼šå†™å…¥ {wrote} æ¡")
            else:
                if not key_val:
                    key_val = str(final_pid or "")
                    if key_val:
                        fields_obj["id"] = key_val
                data_json = json.dumps(fields_obj, ensure_ascii=False)
                import_mode = "upsert"
                sid = st.session_state.get("current_sid", SID)
                wrote = _upsert_entity_row(type_name, key_field, key_val, sid, final_name, data_json, meta, import_mode=import_mode)
                st.success(f"å…¥åº“å®Œæˆï¼šå†™å…¥ {wrote} æ¡")
            st.stop()

        elif st.button("æ‰¹é‡å…¥åº“å½“å‰æµç¨‹å…¨éƒ¨", key=f"import_all_{flow_sel}"):
            rows = _build_instance_rows()
            def _match_flow(r):
                return str(r.get("flow_define_name","")) == str(flow_sel)
            view = [r for r in rows if _match_flow(r)]
            pids_all = [r.get("proc_inst_id") for r in view]
            pg = st.progress(0)
            total = len(pids_all)
            wrote_sum = 0
            for i, pid0 in enumerate(pids_all or []):
                pg.progress(int(((i) / (total or 1)) * 100))
                if not pid0:
                    continue
                bundle = _build_flow_import_bundle(pid0)
                fields_obj = bundle.get("fields_obj") or {}
                flow_md = bundle.get("flow_md") or ""
                meta = bundle.get("meta") or {}
                type_name = bundle.get("type_name") or ""
                key_field = bundle.get("key_field") or "id"
                key_val = bundle.get("key_val") or ""
                final_name = bundle.get("final_name") or ""
                used_match = bundle.get("match")
                if write_mode == "ä»…ä¿å­˜ source_flow/flow_md è¦†ç›–":
                    if not key_val:
                        key_val = str(pid0 or "")
                        if key_val:
                            fields_obj["id"] = key_val
                    cover_obj = {
                        key_field: key_val,
                        "name": fields_obj.get("name", ""),
                        "bt": fields_obj.get("bt", ""),
                        "type": fields_obj.get("type", type_name),
                        "source_flow": fields_obj.get("source_flow",""),
                        "flow_md": flow_md
                    }
                    data_json = json.dumps(cover_obj, ensure_ascii=False)
                    import_mode = "upsert_replace"
                else:
                    if not key_val:
                        key_val = str(pid0 or "")
                        if key_val:
                            fields_obj["id"] = key_val
                    data_json = json.dumps(fields_obj, ensure_ascii=False)
                    import_mode = "upsert"
                sid = st.session_state.get("current_sid", SID)
                wrote = _upsert_entity_row(type_name, key_field, key_val, sid, final_name, data_json, meta, import_mode=import_mode)
                wrote_sum += int(wrote or 0)
            pg.progress(100)
            st.success(f"æ‰¹é‡å…¥åº“å®Œæˆï¼šå†™å…¥ {wrote_sum} æ¡")

    with super_tabs[2]:
        tabs = st.tabs(["å®ä¾‹é¢„è§ˆ(JSON)", "æµç¨‹å®šä¹‰", "è¡¨å•åº“", "åˆ†ç±»", "è¡¨è¾¾å¼åº“", "ç›‘å¬å™¨åº“", "å®ä¾‹æŠ„é€", "ç”¨æˆ·ç»„", "å®ä¾‹æ€»è§ˆ", "å…¨éƒ¨å®ä¾‹"]) 

        # å®ä¾‹é¢„è§ˆï¼ˆJSONï¼‰
        with tabs[0]:
            st.subheader("æŒ‰æµç¨‹å®ä¾‹èšåˆï¼ˆJSON é¢„è§ˆï¼‰")
            # é€‰æ‹©å®ä¾‹æ¥æºäºå†å²å®ä¾‹è¡¨
            hi = _read_sql_rows("act_hi_procinst")
            all_pids = [r.get("id_","") for r in hi if r.get("id_")]
            kw = st.text_input("å…³é”®è¯ï¼ˆå®ä¾‹ID/ä¸šåŠ¡é”®ï¼‰", key="json_kw")
            def _match_pid(r):
                s = (kw or "").strip().lower()
                return (not s) or s in str(r.get("id_","")) .lower() or s in str(r.get("business_key_","")) .lower()
            view_pids = [r.get("id_","") for r in hi if _match_pid(r)]
            pid = st.selectbox("é€‰æ‹©å®ä¾‹ID", options=view_pids or all_pids, index=0 if (view_pids or all_pids) else None, key="json_pid")
            if pid:
                data = _build_instance_json(pid)
                st.json(data)
                st.download_button("ä¸‹è½½ JSON", data=json.dumps(data, ensure_ascii=False, indent=2), file_name=f"procinst_{pid}.json", mime="application/json")

        # æµç¨‹å®šä¹‰
        with tabs[1]:
            kw = st.text_input("å…³é”®è¯ï¼ˆå®šä¹‰ID/æ¨¡å‹ID/æè¿°ï¼‰", key="pd_kw")
            recs = _parse_all_inserts("bpm_process_definition_info")
            def _code_of(pd_id: str):
                s = str(pd_id or "")
                return s.split(":")[0] if ":" in s else s
            for r in recs:
                r["_code"] = _code_of(r.get("process_definition_id"))
            code = st.text_input("æŒ‰åˆ†ç±»ç¼–ç è¿‡æ»¤ï¼ˆä¾‹å¦‚ ContractApprovalï¼‰", key="pd_code")
            def _match(r):
                def _has(s):
                    return (kw or "").strip().lower() in str(s or "").lower()
                ok_kw = (not kw) or _has(r.get("process_definition_id")) or _has(r.get("model_id")) or _has(r.get("description"))
                ok_code = (not code) or (str(r.get("_code","")) == code)
                return ok_kw and ok_code
            view = [r for r in recs if _match(r)]
            cols = ["process_definition_id", "model_id", "description", "form_type", "form_id", "_code"]
            st.dataframe([{k: v for k, v in r.items() if k in cols} for r in view], use_container_width=True)

        # è¡¨å•åº“
        with tabs[2]:
            kw = st.text_input("å…³é”®è¯ï¼ˆè¡¨å•å/å¤‡æ³¨ï¼‰", key="form_kw")
            recs = _parse_all_inserts("bpm_form")
            def _match(r):
                s1 = str(r.get("name",""))
                s2 = str(r.get("remark",""))
                return (not kw) or (kw.lower() in s1.lower() or kw.lower() in s2.lower())
            view = [r for r in recs if _match(r)]
            cols = ["id","name","status","remark"]
            st.dataframe([{k: v for k, v in r.items() if k in cols} for r in view], use_container_width=True)

        # åˆ†ç±»
        with tabs[3]:
            recs = _parse_all_inserts("bpm_category")
            cols = ["id","name","code","status","sort"]
            st.dataframe([{k: v for k, v in r.items() if k in cols} for r in recs], use_container_width=True)

        # è¡¨è¾¾å¼åº“
        with tabs[4]:
            kw = st.text_input("å…³é”®è¯ï¼ˆè¡¨è¾¾å¼å/å†…å®¹ï¼‰", key="expr_kw")
            recs = _parse_all_inserts("bpm_process_expression")
            def _match(r):
                s1 = str(r.get("name",""))
                s2 = str(r.get("expression",""))
                return (not kw) or (kw.lower() in s1.lower() or kw.lower() in s2.lower())
            view = [r for r in recs if _match(r)]
            cols = ["id","name","status","expression"]
            st.dataframe([{k: v for k, v in r.items() if k in cols} for r in view], use_container_width=True)

        # ç›‘å¬å™¨åº“
        with tabs[5]:
            kw = st.text_input("å…³é”®è¯ï¼ˆç›‘å¬å™¨å/äº‹ä»¶/å€¼ï¼‰", key="lst_kw")
            recs = _parse_all_inserts("bpm_process_listener")
            def _match(r):
                s1 = str(r.get("name",""))
                s2 = str(r.get("event",""))
                s3 = str(r.get("value",""))
                return (not kw) or (kw.lower() in s1.lower() or kw.lower() in s2.lower() or kw.lower() in s3.lower())
            view = [r for r in recs if _match(r)]
            cols = ["id","name","type","status","event","value_type","value"]
            st.dataframe([{k: v for k, v in r.items() if k in cols} for r in view], use_container_width=True)

        # å®ä¾‹æŠ„é€
        with tabs[6]:
            kw = st.text_input("å…³é”®è¯ï¼ˆå®ä¾‹ID/ä»»åŠ¡ID/åç§°ï¼‰", key="copy_kw")
            recs = _parse_all_inserts("bpm_process_instance_copy")
            def _match(r):
                s1 = str(r.get("process_instance_id",""))
                s2 = str(r.get("task_id",""))
                s3 = str(r.get("task_name",""))
                return (not kw) or (kw.lower() in s1.lower() or kw.lower() in s2.lower() or kw.lower() in s3.lower())
            view = [r for r in recs if _match(r)]
            cols = ["id","user_id","start_user_id","process_instance_id","process_instance_name","task_id","task_name","category"]
            st.dataframe([{k: v for k, v in r.items() if k in cols} for r in view], use_container_width=True)

        # ç”¨æˆ·ç»„
        with tabs[7]:
            recs = _parse_all_inserts("bpm_user_group")
            cols = ["id","name","description","user_ids","status"]
            st.dataframe([{k: v for k, v in r.items() if k in cols} for r in recs], use_container_width=True)

        # å®ä¾‹æ€»è§ˆï¼ˆæŒ‰ process_instance_id èšåˆï¼‰
        with tabs[8]:
            recs = _read_sql_rows("bpm_process_instance_copy")
            if not recs:
                st.info("æš‚æ— å®ä¾‹æ•°æ®ã€‚")
            else:
                from collections import defaultdict
                groups = defaultdict(list)
                for r in recs:
                    pid = str(r.get("process_instance_id","")).strip()
                    if pid:
                        groups[pid].append(r)
                rows = []
                for pid, items in groups.items():
                    name = next((x.get("process_instance_name") for x in items if x.get("process_instance_name")), "")
                    users = sorted({x.get("user_id") for x in items if x.get("user_id")})
                    starters = sorted({x.get("start_user_id") for x in items if x.get("start_user_id")})
                    tasks = sorted({x.get("task_id") for x in items if x.get("task_id")})
                    cats = sorted({x.get("category") for x in items if x.get("category")})
                    ctimes = [x.get("create_time") for x in items if x.get("create_time")]
                    utimes = [x.get("update_time") for x in items if x.get("update_time")]
                    rows.append({
                        "process_instance_id": pid,
                        "process_instance_name": name,
                        "copies": len(items),
                        "users": ",".join(map(str, users)),
                        "starters": ",".join(map(str, starters)),
                        "task_count": len(tasks),
                        "categories": ",".join(map(str, cats)),
                        "first_create_time": min(ctimes) if ctimes else "",
                        "last_update_time": max(utimes) if utimes else "",
                    })
                st.dataframe(rows, use_container_width=True)

        # å…¨éƒ¨å®ä¾‹ï¼ˆè¿è¡Œæ—¶ + å†å²ï¼‰
        with tabs[9]:
            st.subheader("å†å²å®ä¾‹")
            hi = _read_sql_rows("act_hi_procinst")
            hist_cols = ["id_","proc_def_id_","start_time_","end_time_","business_key_"]
            st.dataframe(_pick_cols(hi, hist_cols), use_container_width=True)

            st.subheader("è¿è¡Œæ—¶ï¼šæ‰§è¡Œæ ‘")
            ru_exec = _read_sql_rows("act_ru_execution")
            exec_cols = ["id_","proc_inst_id_","parent_id_","super_exec_","act_id_","is_active_","is_concurrent_","is_scope_"]
            st.dataframe(_pick_cols(ru_exec, exec_cols), use_container_width=True)

            st.subheader("è¿è¡Œæ—¶ï¼šä»»åŠ¡")
            ru_task = _read_sql_rows("act_ru_task")
            task_cols = ["id_","proc_inst_id_","name_","assignee_","owner_","create_time_","due_date_","category_","priority_"]
            st.dataframe(_pick_cols(ru_task, task_cols), use_container_width=True)

            st.subheader("è¿è¡Œæ—¶ï¼šå˜é‡")
            ru_var = _read_sql_rows("act_ru_variable")
            var_cols = ["id_","proc_inst_id_","execution_id_","name_","text_","double_","long_"]
            st.dataframe(_pick_cols(ru_var, var_cols), use_container_width=True)

        # æµç¨‹å®ä¾‹ï¼ˆç»¼åˆï¼‰
        with tabs[9]:
            kw = st.text_input("å…³é”®è¯ï¼ˆå®ä¾‹ID/ä¸šåŠ¡é”®/å®šä¹‰ç¼–ç ï¼‰", key="inst_kw")
            code_filter = st.text_input("æŒ‰å®šä¹‰ç¼–ç è¿‡æ»¤ï¼ˆå¦‚ ContractApprovalï¼‰", key="inst_code")
            rows = _build_instance_rows()
            def _match(r):
                s = (kw or "").strip().lower()
                ok_kw = (not s) or s in str(r.get("proc_inst_id","")).lower() or s in str(r.get("business_key","")).lower() or s in str(r.get("def_code","")).lower()
                ok_code = (not code_filter) or str(r.get("def_code","")) == code_filter
                return ok_kw and ok_code
            view = [r for r in rows if _match(r)]
            cols = [
                "proc_inst_id","proc_def_id","def_code","category","business_key","start_time","end_time",
                "open_task_count","open_task_names","open_assignees","current_activities",
                "hist_task_count","hist_act_count","copy_count","copy_users","def_desc","form_type","form_id","vars"
            ]
            st.dataframe([{k: v for k, v in r.items() if k in cols} for r in view], use_container_width=True)

            # è¯¦æƒ…æŠ½å±‰
            inst_ids = [r.get("proc_inst_id") for r in view]
            if inst_ids:
                sel = st.selectbox("é€‰æ‹©å®ä¾‹IDæŸ¥çœ‹è¯¦æƒ…", options=inst_ids, index=0, key="inst_sel")
                if sel:
                    st.markdown("---")
                    st.subheader("å®ä¾‹è¯¦æƒ…")
                    # è¿è¡Œæ—¶ä»»åŠ¡
                    st.markdown("**è¿è¡Œæ—¶ä»»åŠ¡**")
                    ru_task = _read_sql_rows("act_ru_task")
                    task_cols = ["id_","proc_inst_id_","name_","assignee_","owner_","create_time_","due_date_","category_","priority_"]
                    task_detail = [r for r in ru_task if str(r.get("proc_inst_id_","")) == str(sel)]
                    st.dataframe(_pick_cols(task_detail, task_cols), use_container_width=True)

                    # è¿è¡Œæ—¶æ‰§è¡Œæ ‘
                    st.markdown("**è¿è¡Œæ—¶æ‰§è¡Œæ ‘**")
                    ru_exec = _read_sql_rows("act_ru_execution")
                    exec_cols = ["id_","proc_inst_id_","parent_id_","super_exec_","act_id_","is_active_","is_concurrent_","is_scope_"]
                    exec_detail = [r for r in ru_exec if str(r.get("proc_inst_id_","")) == str(sel)]
                    st.dataframe(_pick_cols(exec_detail, exec_cols), use_container_width=True)

                    # å†å²èŠ‚ç‚¹è½¨è¿¹
                    st.markdown("**å†å²èŠ‚ç‚¹è½¨è¿¹ï¼ˆact_hi_actinstï¼‰**")
                    hi_act = _read_sql_rows("act_hi_actinst")
                    hact_cols = ["id_","proc_inst_id_","act_id_","act_name_","start_time_","end_time_","assignee_","task_id_"]
                    hact_detail = [r for r in hi_act if str(r.get("proc_inst_id_","")) == str(sel)]
                    st.dataframe(_pick_cols(hact_detail, hact_cols), use_container_width=True)

                    # å˜é‡å…¨éƒ¨é”®å€¼
                    st.markdown("**å˜é‡ï¼ˆå…¨éƒ¨ï¼‰**")
                    ru_var = _read_sql_rows("act_ru_variable")
                    def _val(v):
                        return v.get("text_") or v.get("double_") or v.get("long_") or ""
                    var_detail = [r for r in ru_var if str(r.get("proc_inst_id_","")) == str(sel)]
                    var_rows = [{"name_": v.get("name_",""), "value": _val(v), "execution_id_": v.get("execution_id_",""), "id_": v.get("id_","")} for v in var_detail]
                    st.dataframe(var_rows, use_container_width=True)

                    # è¡¨å•é¢„è§ˆï¼ˆç»‘å®š bpm_process_definition_info â†’ bpm_formï¼‰
                    st.markdown("**è¡¨å•é¢„è§ˆ**")
                    hi = _read_sql_rows("act_hi_procinst")
                    curr = next((r for r in hi if str(r.get("id_","")) == str(sel)), None)
                    def _code_of(def_id):
                        s = str(def_id or "")
                        return s.split(":")[0] if ":" in s else s
                    if curr:
                        def_id = curr.get("proc_def_id_","")
                        code = _code_of(def_id)
                        def_info = _read_sql_rows("bpm_process_definition_info")
                        di = next((d for d in def_info if _code_of(d.get("process_definition_id")) == code), None)
                        if di:
                            st.text(f"å®šä¹‰æè¿°ï¼š{di.get('description','')}")
                            st.text(f"è¡¨å•ç±»å‹ï¼š{di.get('form_type','')} è¡¨å•IDï¼š{di.get('form_id','')}")
                            form_type = str(di.get("form_type",""))
                            if form_type == "10" and di.get("form_id"):
                                forms = _read_sql_rows("bpm_form")
                                fi = next((f for f in forms if str(f.get("id","")) == str(di.get("form_id"))), None)
                                if fi:
                                    st.text(f"è¡¨å•åç§°ï¼š{fi.get('name','')} çŠ¶æ€ï¼š{fi.get('status','')}")
                                    st.text(f"å¤‡æ³¨ï¼š{fi.get('remark','')}")
                                    st.text(f"å­—æ®µï¼š{fi.get('fields','')}")
                                else:
                                    st.info("æœªæ‰¾åˆ°å¯¹åº”çš„å…¬å…±è¡¨å•è®°å½•")
                            else:
                                st.text(f"å®šä¹‰å†…ç½®å­—æ®µï¼š{di.get('form_fields','')}")
                                st.text(f"å®šä¹‰å†…ç½®é…ç½®ï¼š{di.get('form_conf','')}")
                        else:
                            st.info("æœªæ‰¾åˆ°å¯¹åº”çš„æµç¨‹å®šä¹‰æ‰©å±•è®°å½•")
            else:
                st.info("æš‚æ— åŒ¹é…çš„å®ä¾‹ã€‚")

def render_file_mgmt():
    st.title("ğŸ“ƒ æ–‡ä»¶ç®¡ç†")
    render_top_tabs('file')
    st.info("æ–‡ä»¶ç®¡ç†ï¼šåœ¨æ­¤ç»Ÿä¸€ç®¡ç†æ–‡ä»¶æ˜ å°„è§„åˆ™ï¼Œå¹¶å¯é¢„è§ˆæ˜ å°„æ•ˆæœã€‚")

    st.subheader("æ–‡ä»¶æ˜ å°„ç®¡ç†")
    tabs = st.tabs(["æ˜ å°„åˆ—è¡¨", "æ–°å¢æ˜ å°„", "é¢„è§ˆè§£æç¤ºä¾‹"])

    with tabs[0]:
        kw = st.text_input("æŒ‰æºè¡¨è¿‡æ»¤", key="file_map_kw")
        all_maps = list_file_mappings()
        view = [m for m in all_maps if (not kw or kw.strip() in (m.get("source_table") or ""))]
        st.dataframe(view, use_container_width=True)
        del_id = st.number_input("åˆ é™¤æ˜ å°„ID", value=0, step=1, key="file_map_del_id")
        if st.button("åˆ é™¤", key="file_map_del_btn"):
            if int(del_id) > 0:
                ok = delete_file_mapping(int(del_id))
                if ok:
                    st.success("å·²åˆ é™¤æ˜ å°„")
                    st.rerun()
                else:
                    st.error("åˆ é™¤å¤±è´¥")

    with tabs[1]:
        st.caption("æ ¹æ®æŒ‡å¼•ï¼šentity_field ä¸ (doc_uuid, doc_name) ä¸èƒ½åŒæ—¶å­˜åœ¨")
        src_tbl = st.selectbox("source_table", options=[r[0] for r in list_tables(include_disabled=True)], key="file_map_src_tbl")
        src_field = st.text_input("source_field", key="file_map_src_field")
        entity = st.selectbox("entity", options=[x.get("target_entity") or "" for x in list_mapped_tables()] + [""], key="file_map_entity")
        entity_field = st.text_input("entity_field", key="file_map_entity_field")
        doc_uuid = st.text_input("doc_uuid", key="file_map_doc_uuid")
        doc_name = st.text_input("doc_name", key="file_map_doc_name")
        desc = st.text_input("å¤‡æ³¨", key="file_map_desc")
        order_idx = st.number_input("æ’åº", value=0, step=1, key="file_map_order")
        enabled = st.checkbox("å¯ç”¨", value=True, key="file_map_enabled")
        if st.button("ä¿å­˜æ˜ å°„", key="file_map_save"):
            ef = (entity_field or "").strip()
            du, dn = (doc_uuid or "").strip(), (doc_name or "").strip()
            if ef and (du or dn):
                st.error("entity_field ä¸ doc_uuid/doc_name ä¸èƒ½åŒæ—¶å¡«å†™")
            elif not src_tbl or not src_field or not entity:
                st.error("è¯·å¡«å†™ source_tableã€source_fieldã€entity")
            else:
                ok = upsert_file_mapping(src_tbl, src_field, entity, ef, du, dn, desc, int(enabled), int(order_idx))
                if ok:
                    st.success("å·²ä¿å­˜æ˜ å°„")
                    st.rerun()
                else:
                    st.error("ä¿å­˜å¤±è´¥")

    with tabs[2]:
        st.caption("ä»æº SQL çš„æ–‡æœ¬å­—æ®µè§£æ æ–‡ä»¶å@URL åˆ—è¡¨ï¼Œå±•ç¤ºè§£æä¸åˆ†å‘ç¤ºä¾‹")
        demo_tbl = st.selectbox("é€‰æ‹©æºè¡¨", options=[r[0] for r in list_tables(include_disabled=True)], key="file_map_demo_tbl")
        rows = _read_sql_rows(demo_tbl)
        cols = st.text_input("æ‰“å°å­—æ®µï¼ˆé€—å·åˆ†éš”ï¼‰", value="need,upload_files", key="file_map_demo_cols")
        pick = [c.strip() for c in cols.split(",") if c.strip()]
        st.json(_pick_cols(rows[:10], pick))
        st.caption("è§£æè§„åˆ™ï¼šæ”¯æŒ 'æ–‡ä»¶å@URL'ï¼Œå¤šä¸ªä»¥é€—å·åˆ†éš”ï¼›URL ä¸­å¯è§£ææ—¥æœŸç‰‡æ®µä½œä¸ºå­˜å‚¨è·¯å¾„ç»´åº¦")


def render_user_dept_mgmt():
    st.title("ğŸ‘¥ ç”¨æˆ·éƒ¨é—¨ç®¡ç†")
    render_top_tabs('user_dept')
    kw = st.text_input("å…³é”®è¯ï¼ˆå§“å/ID/éƒ¨é—¨ï¼‰", key="user_dept_kw")
    only_missing = st.checkbox("ä»…çœ‹ç¼ºå¤±éƒ¨é—¨", value=False, key="user_dept_missing")
    rows = _parse_all_inserts("sys_user")
    umap, dmap = _user_dept_maps()
    data = []
    for r in rows:
        uid = str(r.get("user_id") or "").strip()
        name = str(r.get("nick_name") or "").strip()
        did = str(r.get("dept_id") or "").strip()
        dname = dmap.get(did, "")
        item = {"user_id": uid, "nick_name": name, "dept_id": did, "dept_name": dname}
        if kw:
            s = kw.strip().lower()
            if not (s in uid.lower() or s in name.lower() or s in did.lower() or s in dname.lower()):
                continue
        if only_missing and dname:
            continue
        data.append(item)
    st.dataframe(data, use_container_width=True)
    cols = st.columns([1,1,6])
    with cols[0]:
        if st.button("ğŸ”„ åˆ·æ–°æ˜ å°„", key="user_dept_refresh"):
            global _USER_MAP, _USER_NAME_MAP, _DEPT_MAP
            _USER_MAP = None
            _USER_NAME_MAP = None
            _DEPT_MAP = None
            _user_dept_maps()
            st.rerun()


# ================= å…¥å£ =================
def main():
    if "page" not in st.session_state:
        st.session_state.page = "list"
        st.session_state.current_table = ""
        st.session_state.current_entity = ""

    q = st.query_params
    if "page" in q:
        st.session_state.page = q["page"]
    if "table" in q:
        st.session_state.current_table = q["table"]
    if "entity" in q:
        st.session_state.current_entity = q["entity"]

    if st.session_state.page == "list":
        render_table_list()
    elif st.session_state.page == "multi_mapping":
        render_multi_mapping()
    elif st.session_state.page == "mapped":
        render_mapped_tables()
    elif st.session_state.page == "flow":
        render_flow_mgmt()
    elif st.session_state.page == "user_dept":
        render_user_dept_mgmt()
    elif st.session_state.page == "file":
        render_file_mgmt()
    elif st.session_state.page == "home":
        render_table_list()
    else:
        render_table_detail(st.session_state.current_table)
if __name__ == "__main__":
    main()
